{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join as oj\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, RidgeCV\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "import eli5\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "plt.style.use('dark_background')\n",
    "import mat4py\n",
    "import pandas as pd\n",
    "import data_tracks\n",
    "from skorch.callbacks import Checkpoint, TrainEndCheckpoint\n",
    "from skorch import NeuralNetRegressor, NeuralNetClassifier\n",
    "import models\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from colorama import Fore\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_tracks.get_tracks() # note: different Xs can be different shapes\n",
    "df = data_tracks.remove_invalid_tracks(df)\n",
    "df = data_tracks.preprocess(df)\n",
    "df = data_tracks.add_outcome(df)\n",
    "n = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "# predict using the trace\n",
    "X_mat = data_tracks.extract_X_mat(df)\n",
    "X_mat -= np.mean(X_mat)\n",
    "X_mat /= np.std(X_mat)\n",
    "outcome = df['outcome'].values.astype(np.int64)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_mat, outcome, test_size=0.33, random_state=42)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_r, Y_train_r = ros.fit_resample(X_train, Y_train)\n",
    "\n",
    "\n",
    "\n",
    "conv_size = 20\n",
    "num_channels = 3\n",
    "dirname = oj('out', f'classification_conv_size={conv_size}_num_channels={num_channels}')\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    nn.Sequential(models.MaxConv(kernel_size=conv_size, num_units=num_channels), \n",
    "                  nn.Linear(1, 2), nn.Softmax()),\n",
    "    max_epochs=10000,\n",
    "    lr=1e-3,\n",
    "    iterator_train__shuffle=True,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    callbacks=[Checkpoint(dirname=dirname)],\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "net.fit(X_train_r, Y_train_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize model\n",
    "'''\n",
    "\n",
    "# load trained model and plot\n",
    "net.initialize() # This is important!\n",
    "net.load_params(\n",
    "    f_params=oj(dirname, 'params.pt'), f_optimizer=oj(dirname, 'optimizer.pt'), f_history=oj(dirname, 'history.json')\n",
    ")\n",
    "\n",
    "R, C = 1, 3\n",
    "plt.figure(figsize=(3 * C, 3 * R))\n",
    "ws = net.module_.state_dict()['0.conv1.weight'].cpu().numpy().squeeze()\n",
    "# print(ws.shape)\n",
    "\n",
    "plt.subplot(R, C, 1)\n",
    "plt.title(f'filters (offset ={net.module_.state_dict()[\"0.offset\"].cpu().numpy().squeeze():0.3f})')\n",
    "plt.plot(ws.T)\n",
    "plt.xlabel('t')\n",
    "\n",
    "plt.subplot(R, C, 2)\n",
    "preds = net.predict_proba(X_test)\n",
    "preds_labels = net.predict(X_test)\n",
    "# plt.plot(Y_train, preds[:, 1], 'o', alpha=0.01)\n",
    "plt.hist(preds[:, 1][Y_test == 0], label='y=0', alpha=0.5)\n",
    "plt.hist(preds[:, 1][Y_test == 1], label='y=1', alpha=0.5)\n",
    "plt.title(f'acc {np.mean(Y_test == preds_labels):0.2f} balanced: {metrics.balanced_accuracy_score(Y_test, preds_labels):0.2f}' ) #' r2 {metrics.r2_score(Y_train, preds):0.2f}')\n",
    "# plt.xlabel('Y')\n",
    "plt.legend()\n",
    "plt.xlabel('pred')\n",
    "\n",
    "plt.subplot(R, C, 3)\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(Y_test, preds[:, 1])\n",
    "plt.plot(precision, recall)\n",
    "plt.xlim((0, 1.05))\n",
    "plt.ylim((0, 1.05))\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(dirname + '.png')\n",
    "plt.show()\n",
    "\n",
    "print(f'class imbalance {np.mean(Y_test):0.2f}')\n",
    "print(f'acc {np.mean(Y_test == preds_labels):0.2f}')\n",
    "print(f'roc_auc {metrics.roc_auc_score(Y_test, preds_labels):0.2f}')\n",
    "print(f'balanced acc: {metrics.balanced_accuracy_score(Y_test, preds_labels):0.2f}') #' r2 {metrics.r2_score(Y_train, preds):0.2f}')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
