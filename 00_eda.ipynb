{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join as oj\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, RidgeCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.decomposition import DictionaryLearning, NMF\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "plt.style.use('dark_background')\n",
    "import mat4py\n",
    "import pandas as pd\n",
    "import data_tracks\n",
    "from skorch.callbacks import Checkpoint, TrainEndCheckpoint\n",
    "from skorch import NeuralNetRegressor, NeuralNetClassifier\n",
    "import models\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pickle as pkl\n",
    "from style import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_tracks.get_data()\n",
    "n = df.shape[0]\n",
    "df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualize a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a single interesting example\n",
    "ex = df[df.lifetime > 250].iloc[0]\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "plt.plot(ex['X'], color='red')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Clathrin intensity')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(dpi=200)\n",
    "plt.plot(ex['X'], color='red')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Clathrin intensity')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(ex['x_pos_seq'][:20], ex['y_pos_seq'][:20])\n",
    "plt.xlabel('x position')\n",
    "plt.ylabel('y position')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# basic eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is the first channel (clathrin)\n",
    "# R, C = 1, 1\n",
    "plt.figure(figsize=(16, 10))\n",
    "R, C = 5, 8\n",
    "for i in range(R * C):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    row = df.iloc[i]\n",
    "    plt.plot(row.X, color='red', label='clathrin')\n",
    "    plt.plot(row.Y, color='green', label='auxilin')\n",
    "#     plt.axi('off')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['x_pos'], df['y_pos'], 'o', alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat4py\n",
    "fname = f'/scratch/users/vision/data/abc_data/auxilin_data_tracked/A7D2/Cell1_1s/TagRFP/Tracking/ProcessedTracks.mat'\n",
    "mat = mat4py.loadmat(fname)\n",
    "tracks = mat['tracks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1790"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tracks['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clath 300 aux 300\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "x = tracks['x'][i][0]\n",
    "xx = tracks['x'][i][1]\n",
    "\n",
    "print('clath', len(x), 'aux', len(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print(tracks['t'][i][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dictionary learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s = df[df.cell_num.isin([1, 2, 3, 4, 5])]\n",
    "X_mat = data_tracks.extract_X_mat(df_s)\n",
    "X_mat -= np.min(X_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse coding\n",
    "def sparse_code(n_comps=12, alpha=1, out_dir='processed/dictionaries'):\n",
    "    d = DictionaryLearning(n_components=n_comps, alpha=alpha)\n",
    "    d.fit(X_mat)\n",
    "    pkl.dump(d, open(oj(out_dir, f'sc_{n_comps}_alpha={alpha}.pkl', 'wb')))\n",
    "    \n",
    "def nmf(n_comps=12, out_dir='processed/dictionaries'):\n",
    "    # nmf\n",
    "    d = NMF(n_components=n_comps)\n",
    "    d.fit(X_mat)\n",
    "    pkl.dump(d, open(oj(out_dir, f'nmf_{n_comps}.pkl', 'wb')))\n",
    "    \n",
    "sparse_code()\n",
    "nmf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sc_12_alpha=1.pkl', 'nmf_12.pkl', '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('dictionaries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pkl.load(open(f'dictionaries/' + 'sc_12_alpha=1.pkl', 'rb'))\n",
    "# d = pkl.load(open(f'dictionaries/' + 'nmf_12.pkl', 'rb'))\n",
    "d.transform(X_mat).shape\n",
    "R, C = 3, 4\n",
    "i = 0\n",
    "plt.figure(dpi=200)\n",
    "vmin = d.components_.min()\n",
    "vmax = d.components_.max()\n",
    "# print('err', d.reconstruction_err_ / np.linalg.norm(X_mat, ord='fro'))\n",
    "for r in range(R):\n",
    "    for c in range(C):\n",
    "        plt.subplot(R, C, i + 1)\n",
    "        plt.plot(d.components_[i], color=cr)\n",
    "        i += 1\n",
    "        plt.ylim((vmin, vmax))\n",
    "        if r < R-1:\n",
    "            plt.xticks([])\n",
    "        if c > 0:\n",
    "            plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
