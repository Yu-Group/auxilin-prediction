{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join as oj\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "# plt.style.use('dark_background')\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import data\n",
    "import pickle as pkl\n",
    "import viz\n",
    "from viz import *\n",
    "import analyze_helper, train\n",
    "from sklearn import metrics\n",
    "from config import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# select model directory + model name\n",
    "# out_dir = oj(DIR_RESULTS, 'may7_1') # mar7_2 is 0.95, mar8_1 is 0.96\n",
    "# out_dir = oj(DIR_RESULTS, 'nov16') # mar7_2 is 0.95, mar8_1 is 0.96\n",
    "out_dir = '../models'\n",
    "r = analyze_helper.load_results(out_dir)\n",
    "r = r.sort_values('accuracy', ascending=False)\n",
    "idx = np.array(r.index)\n",
    "accs = np.array(r.accuracy)\n",
    "model_name = idx[0]\n",
    "# model_name = 'mlp2_17_select_lasso=7_ros=1_h=0_cal=True'\n",
    "\n",
    "# print accs\n",
    "print('using model', model_name)\n",
    "for i in range(min(accs.size, 5)):\n",
    "    print(f'\\t{accs[i]:.3f}', idx[i])\n",
    "\n",
    "# get data\n",
    "outcome_def = 'y_consec_thresh'\n",
    "df = data.get_data()\n",
    "n = df.shape[0]\n",
    "df_cv = df[df.valid == 1] # exclude test cells, short/long tracks, hotspots\n",
    "X, y, norms = analyze_helper.normalize(df_cv, outcome_def)\n",
    "\n",
    "# load model + preds\n",
    "d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_name, out_dir, df_cv.cell_num, X, y)\n",
    "y_full_cv = df_cv[outcome_def].iloc[idxs_cv].values.astype(np.int)\n",
    "preds_cv = d_full_cv[model_name].values\n",
    "preds_proba_cv = d_full_cv[model_name + '_proba'].values\n",
    "\n",
    "results_individual = pkl.load(open(oj(out_dir, f'{model_name}.pkl'), 'rb'))\n",
    "assert np.sum(idxs_cv == np.arange(idxs_cv.size)) == idxs_cv.size, \\\n",
    "       'points not in same order'\n",
    "assert np.mean(preds_cv==y_full_cv) == np.average(results_individual['cv']['accuracy'], \n",
    "                                               weights=results_individual['num_pts_by_fold_cv']), \\\n",
    "        'did not properly load model/data'\n",
    "tp, tn, fp, fn = analyze_helper.calc_errs(preds_cv, y_full_cv)\n",
    "print('succesfully loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracies on different test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate predictions on diff datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [00:21<00:02,  2.64s/it]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9ad0a5a9ae4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mdset_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDSETS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0morig_dset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_proba_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_and_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_names_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_by_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mdsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mys_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/chandan/auxilin-prediction/src/analyze_helper.py\u001b[0m in \u001b[0;36mnormalize_and_predict\u001b[0;34m(m0, feat_names_selected, dset_name, normalize_by_train, outcome_def)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0my_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcome_def\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     \u001b[0mpreds_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_names_selected\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m     \u001b[0mpreds_proba_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeat_names_selected\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mY_maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Y_max'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \"\"\"\n\u001b[1;32m    233\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mmean_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcalibrated_classifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrated_classifiers_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalibrated_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mmean_proba\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_pos_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthis_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalibrator\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/calibration.py\u001b[0m in \u001b[0;36m_preproc\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict_proba\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \"\"\"\n\u001b[1;32m   1104\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \"\"\"\n\u001b[0;32m--> 681\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;31m# Make sure self.hidden_layer_sizes is a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 645\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     (type_err,\n\u001b[0;32m---> 99\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    100\u001b[0m             )\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "orig_dset = 'clath_aux+gak_a7d2'\n",
    "normalize_by_train = False\n",
    "df = data.get_data()\n",
    "\n",
    "# training data\n",
    "CELLS_TRAIN = config.DSETS[orig_dset]['train']\n",
    "df_train = df[df.cell_num.isin(CELLS_TRAIN)]\n",
    "X_train = df_train[data.get_feature_names(df_train)]\n",
    "X_mean_train = X_train.mean()\n",
    "X_std_train = X_train.std()\n",
    "\n",
    "# testing data\n",
    "CELLS_TEST = config.DSETS[orig_dset]['test']\n",
    "df_test = df[df.cell_num.isin(CELLS_TEST)]\n",
    "X_test = df_test[data.get_feature_names(df_test)]\n",
    "if normalize_by_train:\n",
    "    X_test = (X_test - X_mean_train) / X_std_train\n",
    "else:\n",
    "    X_test = (X_test - X_test.mean()) / X_test.std()\n",
    "y_test = df_test[outcome_def].values\n",
    "\n",
    "# get model\n",
    "m0 = results_individual['imps']['model'][0]\n",
    "feat_names_selected = results_individual['feat_names_selected']\n",
    "preds_test = m0.predict(X_test[feat_names_selected]) \n",
    "preds_proba_test = m0.predict_proba(X_test[feat_names_selected]) [:, 1]\n",
    "\n",
    "# set up lists\n",
    "dsets = ['validation', 'test']\n",
    "ys_list = [y_full_cv, y_test]\n",
    "preds_list = [preds_cv, preds_test]\n",
    "preds_proba_list = [preds_proba_cv, preds_proba_test]\n",
    "Y_max_list = [df_cv['Y_max'], df_test['Y_max']]\n",
    "\n",
    "# loop over new datasets\n",
    "outcome_def = 'y_consec_thresh'\n",
    "# outcome_def = 'y_rule_based'\n",
    "dset_names = [k for k in config.DSETS.keys() if not k == orig_dset]\n",
    "for dset_name in tqdm(dset_names):\n",
    "    _, y_new, preds_new, preds_proba_new, Y_maxes = analyze_helper.normalize_and_predict(m0, feat_names_selected, dset_name, normalize_by_train)\n",
    "    dsets.append(dset_name)\n",
    "    ys_list.append(deepcopy(y_new))\n",
    "    preds_list.append(deepcopy(preds_new))\n",
    "    preds_proba_list.append(deepcopy(preds_proba_new))\n",
    "    Y_max_list.append(Y_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**show metrics on different dsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dsets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01c5deb46721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mr_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dsets' is not defined"
     ]
    }
   ],
   "source": [
    "def roundd(x):\n",
    "    try:\n",
    "        return x.round(2)\n",
    "    except:\n",
    "        return [y.round(2) for y in x]\n",
    "    \n",
    "def mean_diff(vals, preds):\n",
    "    return np.mean(vals[preds==1]) - np.mean(vals[preds==0])\n",
    "\n",
    "r_long = {}\n",
    "n = len(dsets)\n",
    "for s in train.scorers:\n",
    "    if s == 'roc_auc':\n",
    "        r_long[s] = [roundd(metrics.roc_auc_score(ys_list[i],\n",
    "                                                  preds_proba_list[i])) for i in range(n)]\n",
    "    elif 'curve' not in s and 'acc' in s:\n",
    "        r_long[s] = [roundd(train.scorers[s](ys_list[i], preds_list[i])) for i in range(n)]        \n",
    "r_long['diff_aux_max_by_class'] = [mean_diff(Y_max_list[i], preds_list[i]) for i in range(n)]\n",
    "r_long['aux+ ratio'] = [np.mean(ys_list[i]) for i in range(n)]\n",
    "\n",
    "r = pd.DataFrame.from_dict(r_long).transpose()\n",
    "r.columns = dsets\n",
    "r.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diff dataset summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process original data (and save out lifetime thresholds)\n",
    "dset_names = [k for k in sorted(config.DSETS.keys()) if not 'pi4p' in k]\n",
    "# dsets = ['clath_aux', 'orig_gak', 'clath_aux_no_a7d2', 'clath_aux_a8', 'clath_pi4p_notreatment']\n",
    "\n",
    "NUM_DSETS = len(dset_names)\n",
    "rs = {\n",
    "    k: [] for k in ['X_mean', 'Y_max']\n",
    "}\n",
    "ds = {\n",
    "    k: [] for k in ['lifetime', 'Y_max']\n",
    "}\n",
    "for dset in tqdm(dset_names):\n",
    "    # process new data (using lifetime thresholds from original data)\n",
    "    df = data.get_data(dset=dset,\n",
    "                  previous_meta_file='processed/metadata_orig.pkl')\n",
    "    for k in rs.keys():\n",
    "        rs[k].append(df[k].mean())\n",
    "    for k in ds.keys():\n",
    "        ds[k].append(df[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**means of some features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, C = 1, 2\n",
    "plt.figure(figsize=(8, 3), dpi=500)\n",
    "for i, k in enumerate(rs.keys()):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.barh(dset_names, rs[k], color=cb)\n",
    "    plt.xlabel('Average ' + k)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, C = 1, len(ds.keys())\n",
    "plt.figure(figsize=(8, 3), dpi=500)\n",
    "for i, k in enumerate(ds.keys()):\n",
    "    ax = plt.subplot(R, C, i + 1)\n",
    "    # plt.barh(dset_names, [np.mean(x) for x in ds[k]], color=cb)\n",
    "    ax.violinplot([val.values for val in ds[k]], vert=False,\n",
    "                  widths=1, showmedians=True, showextrema=True) #, quantiles=[25, 50])\n",
    "    plt.yticks(np.arange(len(dset_names)) + 1, dset_names)\n",
    "    plt.xlabel(k)\n",
    "    plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower res data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "DOWNSAMPLE_list = range(1, 21)\n",
    "for DOWNSAMPLE in tqdm(DOWNSAMPLE_list):\n",
    "\n",
    "    # downsample\n",
    "    df_cv = deepcopy(df[df.valid == 1]) # exclude test cells, short/long tracks, hotspots\n",
    "    df_cv['X'] = [x[::DOWNSAMPLE] for x in df_cv.X]\n",
    "    df_cv['X_extended'] = [x[::DOWNSAMPLE] for x in df_cv.X_extended]\n",
    "    df_cv['lifetime'] = [len(x) for x in df_cv.X]\n",
    "    df_cv = data.add_features(df_cv)\n",
    "\n",
    "\n",
    "    # get data\n",
    "    X, y, norms = analyze_helper.normalize(df_cv, outcome_def)\n",
    "    d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_name, out_dir, df_cv.cell_num, X, y)\n",
    "    y_full_cv = df_cv[outcome_def].iloc[idxs_cv].values.astype(np.int)\n",
    "    preds = d_full_cv[model_name].values\n",
    "    preds_proba = d_full_cv[model_name + '_proba'].values\n",
    "    acc = np.mean(preds==y_full_cv)\n",
    "    accs.append(acc)\n",
    "#     print(f'downsampling rate {DOWNSAMPLE} acc {acc.round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.plot(DOWNSAMPLE_list, accs, '.-', color=cb)\n",
    "plt.xlabel('Downsamping factor')\n",
    "plt.ylabel('Accuracy on difficult region')\n",
    "plt.savefig('downampling.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of example track\n",
    "track_num = 3\n",
    "ex = deepcopy(df[df.valid == 1]).iloc[track_num]\n",
    "viz.plot_example(ex)\n",
    "plt.plot(np.arange(len(ex.X))[::3], ex.X[::3], 'o', color='w', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dynamin analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_name = 'clath_aux_dynamin'\n",
    "df_new, y_new, preds_new, preds_proba_new, Y_maxes = \\\n",
    "    normalize_and_predict(dset_name, normalize_by_train=False)\n",
    "tp, tn, fp, fn = analyze_helper.calc_errs(preds_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the biggest errors\n",
    "num_to_plot = 25\n",
    "# print('total pts', preds.shape[0])\n",
    "# for idxs, name in zip([fp, fn, tp, tn], ['fp', 'fn', 'tp', 'tn']):\n",
    "for idxs, name in zip([fp, fn], ['fp', 'fn']):\n",
    "# for idxs, name in zip([tp, tn], ['tp', 'tn']):\n",
    "    print(name)\n",
    "    inds = viz.viz_biggest_errs(df_new, None, idxs,\n",
    "                                y_new,\n",
    "                                preds_new,\n",
    "                                preds_proba_new,\n",
    "                                num_to_plot,\n",
    "                                plot_x=True,\n",
    "                                plot_z=True,\n",
    "                                xlim_constant=False)\n",
    "    plt.legend()\n",
    "#     plt.savefig(f'{name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the biggest errors\n",
    "num_to_plot = 50\n",
    "# print('total pts', preds.shape[0])\n",
    "# for idxs, name in zip([fp, fn, tp, tn], ['fp', 'fn', 'tp', 'tn']):\n",
    "for idxs, name in zip([fp], ['fp']):\n",
    "# for idxs, name in zip([tp, tn], ['tp', 'tn']):\n",
    "    print(name)\n",
    "    inds = viz.viz_biggest_errs(df_new, None, idxs,\n",
    "                                y_new,\n",
    "                                preds_new,\n",
    "                                preds_proba_new,\n",
    "                                num_to_plot,\n",
    "                                plot_x=False,\n",
    "                                plot_z=True,\n",
    "                                xlim_constant=False)\n",
    "#     plt.legend()\n",
    "#     plt.savefig(f'{name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "df_new['Z_max'] = [max(z) for z in df_new['Z']]\n",
    "df_new['Z_max_normed'] = norm(df_new['Z_max'])\n",
    "df_new['Y_max_normed'] = norm(df_new['Y_max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(df_new[fp]['Y_max'], df_new[fp]['Z_max'],\n",
    "         'o', alpha=0.3, ms=0.5)\n",
    "plt.xlabel('aux max')\n",
    "plt.ylabel('dyn max')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 9))\n",
    "zs = sorted(df_new[fp]['Z_max'])[::-1]\n",
    "plt.plot(100 * np.arange(len(zs)) / len(zs), zs)\n",
    "\n",
    "# plt.xlim((0, 10))\n",
    "plt.grid(alpha=0.2)\n",
    "plt.ylabel('dyn max')\n",
    "plt.xlabel('Percent of false positives')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4.5), dpi=200)\n",
    "zs = sorted(df_new[fp]['Z_max'])[::-1]\n",
    "plt.plot(np.arange(len(zs)), zs, label='false positive')\n",
    "\n",
    "zs2 = sorted(df_new[tn]['Z_max'])[::-1]\n",
    "plt.plot(np.arange(len(zs2)), zs2, label='true negative')\n",
    "\n",
    "# plt.xlim((-50, 2500))\n",
    "plt.legend(fontsize=20)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.ylabel('dyn max')\n",
    "plt.xlabel('Number of tracks')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, C = 6, 6\n",
    "ylim_constant=False\n",
    "xlim_constant=True\n",
    "legend=True\n",
    "plot_x=True\n",
    "lifetime_max = np.max(df.lifetime.values[:R * C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(0, df_new.shape[0], R*C - 1)\n",
    "d = df_new.sort_values('Z_max').iloc[np.linspace(35000, df_new.shape[0] - 1, R*C).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "for i in tqdm(range(R * C)):\n",
    "    if i < d.shape[0]:\n",
    "        plt.subplot(R, C, i + 1)\n",
    "        row = d.iloc[i]\n",
    "        if plot_x:\n",
    "            plt.plot(row.X, color=cr, label='clathrin')\n",
    "#         if extra_key is not None:\n",
    "        plt.plot(row.Z, color=cp, label='dyn')\n",
    "        plt.title(int(row.Z_max), color=cp)\n",
    "        if ylim_constant:\n",
    "            plt.ylim([-10, max(max(d.X_max), max(d.Y_max)) + 1])\n",
    "        plt.axhline(642.3754691658837, color='gray', alpha=0.5)\n",
    "        plt.xticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
