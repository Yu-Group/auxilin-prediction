{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator _SigmoidCalibration from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator SelectFromModel from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator Lasso from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator SVC from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model mlp2_17_select_lasso=7_ros=1_h=0_cal=True\n",
      "\t0.760 svm_17_select_lasso=9_ros=1.2_h=1_cal=True\n",
      "\t0.760 svm_17_select_lasso=9_ros=1_h=1_cal=True\n",
      "\t0.759 mlp2_17_select_lasso=9_ros=1_h=1_cal=True\n",
      "\t0.758 mlp2_17_select_lasso=15_ros=1_h=0_cal=True\n",
      "\t0.757 mlp2_17_select_lasso=9_ros=1_h=0_cal=True\n",
      "succesfully loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator _SigmoidCalibration from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator Lasso from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator SelectFromModel from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator MLPClassifier from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelBinarizer from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator _SigmoidCalibration from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator CalibratedClassifierCV from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator Lasso from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/accounts/projects/vision/.local/lib/python3.7/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator SelectFromModel from version 0.22 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join as oj\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "plt.style.use('dark_background')\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import data\n",
    "import pickle as pkl\n",
    "import viz\n",
    "from viz import *\n",
    "import analyze_helper, train\n",
    "from sklearn import metrics\n",
    "from config import *\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "outcome_def = 'y_consec_thresh'\n",
    "out_dir = oj(DIR_RESULTS, 'may7_1') # mar7_2 is 0.95, mar8_1 is 0.96\n",
    "results = analyze_helper.load_results(out_dir)\n",
    "\n",
    "# get data\n",
    "df = data.get_data()\n",
    "n = df.shape[0]\n",
    "df_cv = df[df.valid == 1] # exclude test cells, short/long tracks, hotspots\n",
    "X, y, norms = analyze_helper.normalize(df_cv, outcome_def)\n",
    "\n",
    "# select model\n",
    "r = results\n",
    "r = r.sort_values('accuracy', ascending=False)\n",
    "idx = np.array(r.index)\n",
    "accs = np.array(r.accuracy)\n",
    "# model_name = idx[0]\n",
    "model_name = 'mlp2_17_select_lasso=7_ros=1_h=0_cal=True'\n",
    "print('using model', model_name)\n",
    "for i in range(5):\n",
    "    print(f'\\t{accs[i]:.3f}', idx[i])\n",
    "    \n",
    "\n",
    "# load model + preds\n",
    "d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_name, out_dir, df_cv.cell_num, X, y)\n",
    "y_full_cv = df_cv[outcome_def].iloc[idxs_cv].values.astype(np.int)\n",
    "preds_cv = d_full_cv[model_name].values\n",
    "preds_proba_cv = d_full_cv[model_name + '_proba'].values\n",
    "\n",
    "results_individual = pkl.load(open(oj(out_dir, f'{model_name}.pkl'), 'rb'))\n",
    "assert np.sum(idxs_cv == np.arange(idxs_cv.size)) == idxs_cv.size, \\\n",
    "       'points not in same order'\n",
    "assert np.mean(preds_cv==y_full_cv) == np.average(results_individual['cv']['accuracy'], \n",
    "                                               weights=results_individual['num_pts_by_fold_cv']), \\\n",
    "        'did not properly load model/data'\n",
    "tp, tn, fp, fn = analyze_helper.calc_errs(preds_cv, y_full_cv)\n",
    "print('succesfully loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# accuracies on different test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate predictions on diff datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█▍        | 1/7 [00:00<00:03,  1.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|██▊       | 2/7 [00:05<00:08,  1.77s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████▎     | 3/7 [00:22<00:25,  6.32s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████▋    | 4/7 [00:25<00:16,  5.48s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████▏  | 5/7 [00:26<00:08,  4.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████▌ | 6/7 [00:28<00:03,  3.39s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 7/7 [00:28<00:00,  2.56s/it]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "orig_dset = 'clath_aux+gak_a7d2'\n",
    "normalize_by_train = False\n",
    "df = data.get_data()\n",
    "\n",
    "# training data\n",
    "CELLS_TRAIN = config.DSETS[orig_dset]['train']\n",
    "df_train = df[df.cell_num.isin(CELLS_TRAIN)]\n",
    "X_train = df_train[data.get_feature_names(df_train)]\n",
    "X_mean_train = X_train.mean()\n",
    "X_std_train = X_train.std()\n",
    "\n",
    "# testing data\n",
    "CELLS_TEST = config.DSETS[orig_dset]['test']\n",
    "df_test = df[df.cell_num.isin(CELLS_TEST)]\n",
    "X_test = df_test[data.get_feature_names(df_test)]\n",
    "if normalize_by_train:\n",
    "    X_test = (X_test - X_mean_train) / X_std_train\n",
    "else:\n",
    "    X_test = (X_test - X_test.mean()) / X_test.std()\n",
    "y_test = df_test[outcome_def].values\n",
    "\n",
    "# get model\n",
    "m0 = results_individual['imps']['model'][0]\n",
    "feat_names_selected = results_individual['feat_names_selected']\n",
    "preds_test = m0.predict(X_test[feat_names_selected]) \n",
    "preds_proba_test = m0.predict_proba(X_test[feat_names_selected]) [:, 1]\n",
    "\n",
    "# set up lists\n",
    "dsets = ['validation', 'test']\n",
    "ys_list = [y_full_cv, y_test]\n",
    "preds_list = [preds_cv, preds_test]\n",
    "preds_proba_list = [preds_proba_cv, preds_proba_test]\n",
    "Y_max_list = [df_cv['Y_max'], df_test['Y_max']]\n",
    "\n",
    "def normalize_and_predict(dset_name, normalize_by_train):\n",
    "    df_new = data.get_data(dset=dset_name, use_processed=True,\n",
    "                           use_processed_dicts=True, outcome_def=outcome_def,\n",
    "                           previous_meta_file=oj(DIR_PROCESSED,\n",
    "                                                 'metadata_clath_aux+gak_a7d2.pkl'))\n",
    "    df_new = df_new[df_new['valid']] # exclude test cells, short/long tracks, hotspots\n",
    "    \n",
    "    # impute (only does anything for dynamin data)\n",
    "    df_new = df_new.fillna(df_new.median())\n",
    "    \n",
    "    X_new = df_new[data.get_feature_names(df_new)]\n",
    "    if normalize_by_train:\n",
    "        X_new = (X_new - X_mean_train) / X_std_train\n",
    "    else:\n",
    "        X_new = (X_new - X_new.mean()) / X_new.std()\n",
    "    y_new = df_new[outcome_def].values\n",
    "    preds_new = m0.predict(X_new[feat_names_selected]) \n",
    "    preds_proba_new = m0.predict_proba(X_new[feat_names_selected])[:, 1]\n",
    "    Y_maxes = df_new['Y_max']\n",
    "    return df_new, y_new, preds_new, preds_proba_new, Y_maxes\n",
    "\n",
    "# loop over new datasets\n",
    "dset_names = [k for k in config.DSETS.keys() if not k == orig_dset]\n",
    "for dset_name in tqdm(dset_names):\n",
    "    _, y_new, preds_new, preds_proba_new, Y_maxes = normalize_and_predict(dset_name, normalize_by_train)\n",
    "    dsets.append(dset_name)\n",
    "    ys_list.append(deepcopy(y_new))\n",
    "    preds_list.append(deepcopy(preds_new))\n",
    "    preds_proba_list.append(deepcopy(preds_proba_new))\n",
    "    Y_max_list.append(Y_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**show metrics on different dsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "      <th>clath_aux+gak</th>\n",
       "      <th>clath_aux+gak_a7d2_new</th>\n",
       "      <th>clath_aux_dynamin</th>\n",
       "      <th>clath_aux+gak_new</th>\n",
       "      <th>clath_gak</th>\n",
       "      <th>clath_pi4p_notreatment</th>\n",
       "      <th>ap2_pi4p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_aux_max_by_class</th>\n",
       "      <td>481.56</td>\n",
       "      <td>552.96</td>\n",
       "      <td>1346.36</td>\n",
       "      <td>1838.80</td>\n",
       "      <td>539.72</td>\n",
       "      <td>1253.91</td>\n",
       "      <td>509.87</td>\n",
       "      <td>5276.23</td>\n",
       "      <td>6708.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aux+ ratio</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       validation    test  clath_aux+gak  \\\n",
       "balanced_accuracy            0.74    0.77           0.75   \n",
       "accuracy                     0.74    0.69           0.75   \n",
       "roc_auc                      0.81    0.88           0.81   \n",
       "diff_aux_max_by_class      481.56  552.96        1346.36   \n",
       "aux+ ratio                   0.50    0.22           0.60   \n",
       "\n",
       "                       clath_aux+gak_a7d2_new  clath_aux_dynamin  \\\n",
       "balanced_accuracy                        0.66               0.69   \n",
       "accuracy                                 0.64               0.63   \n",
       "roc_auc                                  0.71               0.79   \n",
       "diff_aux_max_by_class                 1838.80             539.72   \n",
       "aux+ ratio                               0.70               0.26   \n",
       "\n",
       "                       clath_aux+gak_new  clath_gak  clath_pi4p_notreatment  \\\n",
       "balanced_accuracy                   0.76       0.69                    0.75   \n",
       "accuracy                            0.76       0.67                    0.54   \n",
       "roc_auc                             0.83       0.74                    0.84   \n",
       "diff_aux_max_by_class            1253.91     509.87                 5276.23   \n",
       "aux+ ratio                          0.52       0.40                    0.96   \n",
       "\n",
       "                       ap2_pi4p  \n",
       "balanced_accuracy          0.79  \n",
       "accuracy                   0.58  \n",
       "roc_auc                    0.83  \n",
       "diff_aux_max_by_class   6708.42  \n",
       "aux+ ratio                 1.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def roundd(x):\n",
    "    try:\n",
    "        return x.round(2)\n",
    "    except:\n",
    "        return [y.round(2) for y in x]\n",
    "    \n",
    "def mean_diff(vals, preds):\n",
    "    return np.mean(vals[preds==1]) - np.mean(vals[preds==0])\n",
    "\n",
    "r_long = {}\n",
    "n = len(dsets)\n",
    "for s in train.scorers:\n",
    "    if s == 'roc_auc':\n",
    "        r_long[s] = [roundd(metrics.roc_auc_score(ys_list[i],\n",
    "                                                  preds_proba_list[i])) for i in range(n)]\n",
    "    elif 'curve' not in s and 'acc' in s:\n",
    "        r_long[s] = [roundd(train.scorers[s](ys_list[i], preds_list[i])) for i in range(n)]        \n",
    "r_long['diff_aux_max_by_class'] = [mean_diff(Y_max_list[i], preds_list[i]) for i in range(n)]\n",
    "r_long['aux+ ratio'] = [np.mean(ys_list[i]) for i in range(n)]\n",
    "\n",
    "r = pd.DataFrame.from_dict(r_long).transpose()\n",
    "r.columns = dsets\n",
    "r.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  validation &        test &  clath\\_aux+gak &  clath\\_aux+gak\\_a7d2\\_new &  clath\\_aux\\_dynamin &  clath\\_aux+gak\\_new &   clath\\_gak &  clath\\_pi4p\\_notreatment &     ap2\\_pi4p \\\\\n",
      "\\midrule\n",
      "balanced\\_accuracy     &    0.740000 &    0.770000 &       0.750000 &                0.660000 &           0.690000 &           0.760000 &    0.690000 &                 0.75000 &     0.790000 \\\\\n",
      "accuracy              &    0.740000 &    0.690000 &       0.750000 &                0.640000 &           0.630000 &           0.760000 &    0.670000 &                 0.54000 &     0.580000 \\\\\n",
      "roc\\_auc               &    0.810000 &    0.880000 &       0.810000 &                0.710000 &           0.790000 &           0.830000 &    0.740000 &                 0.84000 &     0.830000 \\\\\n",
      "diff\\_aux\\_max\\_by\\_class &  481.561862 &  552.964877 &    1346.360305 &             1838.796365 &         539.723075 &        1253.913174 &  509.865985 &              5276.23233 &  6708.415769 \\\\\n",
      "aux+ ratio            &    0.504768 &    0.224670 &       0.596165 &                0.696230 &           0.260263 &           0.515695 &    0.402618 &                 0.95671 &     0.998515 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(r.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diff dataset summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 1/6 [00:00<00:01,  4.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 2/6 [00:00<00:01,  2.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 3/6 [00:04<00:03,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 4/6 [00:04<00:02,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 5/6 [00:15<00:03,  3.84s/it]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 6/6 [00:16<00:00,  3.09s/it]\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "# process original data (and save out lifetime thresholds)\n",
    "dset_names = [k for k in sorted(config.DSETS.keys()) if not 'pi4p' in k]\n",
    "# dsets = ['clath_aux', 'orig_gak', 'clath_aux_no_a7d2', 'clath_aux_a8', 'clath_pi4p_notreatment']\n",
    "\n",
    "NUM_DSETS = len(dset_names)\n",
    "rs = {\n",
    "    k: [] for k in ['X_mean', 'Y_max']\n",
    "}\n",
    "ds = {\n",
    "    k: [] for k in ['lifetime']\n",
    "}\n",
    "for dset in tqdm(dset_names):\n",
    "    # process new data (using lifetime thresholds from original data)\n",
    "    df = data.get_data(dset=dset,\n",
    "                  previous_meta_file='processed/metadata_orig.pkl')\n",
    "    for k in rs.keys():\n",
    "        rs[k].append(df[k].mean())\n",
    "    for k in ds.keys():\n",
    "        ds[k].append(df[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**means of some features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, C = 1, 2\n",
    "plt.figure(figsize=(8, 3), dpi=500)\n",
    "for i, k in enumerate(rs.keys()):\n",
    "    plt.subplot(R, C, i + 1)\n",
    "    plt.barh(dset_names, rs[k], color=cb)\n",
    "    plt.xlabel('Average ' + k)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, C = 1, len(ds.keys())\n",
    "plt.figure(figsize=(8, 3), dpi=500)\n",
    "for i, k in enumerate(ds.keys()):\n",
    "    ax = plt.subplot(R, C, i + 1)\n",
    "    # plt.barh(dset_names, [np.mean(x) for x in ds[k]], color=cb)\n",
    "    ax.violinplot([val.values for val in ds[k]], vert=False, widths=1, showmedians=True, showextrema=True) #, quantiles=[25, 50])\n",
    "    plt.yticks(np.arange(len(dset_names)) + 1, dset_names)\n",
    "    plt.xlabel(k)\n",
    "    plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower res data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "DOWNSAMPLE_list = range(1, 21)\n",
    "for DOWNSAMPLE in tqdm(DOWNSAMPLE_list):\n",
    "\n",
    "    # downsample\n",
    "    df_cv = deepcopy(df[df.valid == 1]) # exclude test cells, short/long tracks, hotspots\n",
    "    df_cv['X'] = [x[::DOWNSAMPLE] for x in df_cv.X]\n",
    "    df_cv['X_extended'] = [x[::DOWNSAMPLE] for x in df_cv.X_extended]\n",
    "    df_cv['lifetime'] = [len(x) for x in df_cv.X]\n",
    "    df_cv = data.add_features(df_cv)\n",
    "\n",
    "\n",
    "    # get data\n",
    "    X, y, norms = analyze_helper.normalize(df_cv, outcome_def)\n",
    "    d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_name, out_dir, df_cv.cell_num, X, y)\n",
    "    y_full_cv = df_cv[outcome_def].iloc[idxs_cv].values.astype(np.int)\n",
    "    preds = d_full_cv[model_name].values\n",
    "    preds_proba = d_full_cv[model_name + '_proba'].values\n",
    "    acc = np.mean(preds==y_full_cv)\n",
    "    accs.append(acc)\n",
    "#     print(f'downsampling rate {DOWNSAMPLE} acc {acc.round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.plot(DOWNSAMPLE_list, accs, '.-', color=cb)\n",
    "plt.xlabel('Downsamping factor')\n",
    "plt.ylabel('Accuracy on difficult region')\n",
    "plt.savefig('downampling.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of example track\n",
    "track_num = 3\n",
    "ex = deepcopy(df[df.valid == 1]).iloc[track_num]\n",
    "viz.plot_example(ex)\n",
    "plt.plot(np.arange(len(ex.X))[::3], ex.X[::3], 'o', color='w', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# viz biggest errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lifetime', 'cell_num', 'catIdx', 't', 'mean_total_displacement', 'mean_square_displacement', 'x_pos_seq', 'y_pos_seq', 'x_pos', 'y_pos', 'X_pvals', 'X_extended', 'X', 'X_starts', 'X_ends', 'Y_pvals', 'Y', 'Y_starts', 'Y_ends', 'Z_pvals', 'Z', 'Z_starts', 'Z_ends', 'lifetime_extended', 'pid', 'valid', 'X_max', 'X_max_extended', 'X_min', 'X_mean', 'X_std', 'Y_max', 'Y_mean', 'Y_std', 'X_peak_idx', 'Y_peak_idx', 'X_peak_time_frac', 'slope_end', 'X_peak_last_15', 'X_peak_last_5', 'rise', 'fall', 'rise_extended', 'fall_extended', 'fall_late_extended', 'rise_slope', 'fall_slope', 'rise_local_3', 'fall_local_3', 'rise_local_11', 'fall_local_11', 'max_diff', 'min_diff', 'y_score', 'y_thresh', 'y', 'y_num_sig', 'y_single_sig', 'y_double_sig', 'y_conservative_thresh', 'y_consec_sig', 'y_sig_min_diff', 'y_consec_thresh', 'sig_idxs', 'hotspots', 'Y_peak_time_frac', 'y_z_score', 'X_max_around_Y_peak', 'X_max_after_Y_peak', 'X_max_diff', 'y_rule_based', 'short', 'long']\n"
     ]
    }
   ],
   "source": [
    "dset_name = 'clath_aux_dynamin'\n",
    "df_new, y_new, preds_new, preds_proba_new, Y_maxes = normalize_and_predict(dset_name, normalize_by_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the biggest errors\n",
    "num_to_plot = 25\n",
    "# print('total pts', preds.shape[0])\n",
    "# for idxs, name in zip([fp, fn, tp, tn], ['fp', 'fn', 'tp', 'tn']):\n",
    "for idxs, name in zip([fp, fn], ['fp', 'fn']):\n",
    "# for idxs, name in zip([tp, tn], ['tp', 'tn']):\n",
    "    print(name)\n",
    "    inds = viz.viz_biggest_errs(df_new, None, None,\n",
    "                                y_new,\n",
    "                                preds_new,\n",
    "                                preds_proba_new,\n",
    "                                num_to_plot,\n",
    "                                plot_z=True, xlim_constant=False)\n",
    "#     plt.savefig(f'{name}.pdf')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
