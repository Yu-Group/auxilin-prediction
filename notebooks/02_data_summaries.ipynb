{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import sklearn.calibration\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "# plt.style.use('dark_background')\n",
    "import data\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch import NeuralNetRegressor\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import train_reg\n",
    "from math import floor\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import config\n",
    "import models\n",
    "import pandas as pd\n",
    "import features\n",
    "from scipy.stats import skew, pearsonr\n",
    "import outcomes\n",
    "import neural_networks\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import interpret\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import viz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently trained only on 'clath_aux+gak_a7d2_new'\n",
    "# dsets = ['clath_aux+gak_new']\n",
    "dsets = ['clath_aux_dynamin']\n",
    "splits = ['test']\n",
    "# feat_names = ['X_same_length_normalized'] # + data.select_final_feats(data.get_feature_names(df))\n",
    "\n",
    "#feat_names = ['X_same_length_normalized'] + data.select_final_feats(data.get_feature_names(df))\n",
    "              #['mean_total_displacement', 'mean_square_displacement', 'lifetime']\n",
    "meta = ['cell_num', 'Y_sig_mean', 'Y_sig_mean_normalized']\n",
    "dfs, feat_names = data.load_dfs_for_lstm(dsets=dsets, splits=splits, meta=meta, normalize=False)\n",
    "print('type', type(dfs))\n",
    "# load model\n",
    "p = 1\n",
    "results = pkl.load(open(config.FINAL_MODEL, 'rb'))\n",
    "dnn = neural_networks.neural_net_sklearn(D_in=40, H=20, p=p-1, arch='lstm')\n",
    "dnn.model.load_state_dict(results['model_state_dict'])\n",
    "\n",
    "# load data\n",
    "# df = dfs[('clath_aux+gak_a7d2', 'train')]\n",
    "# df = dfs[('clath_aux+gak_new', 'test')]\n",
    "df = dfs[list(dfs.keys())[0]]\n",
    "X = df[feat_names[:p]]\n",
    "y = df['y_consec_thresh']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.839 vs baseline 0.66\n"
     ]
    }
   ],
   "source": [
    "track_name = 'X_same_length_normalized'\n",
    "track_name_unnormalized = 'X_same_length'\n",
    "# df = dfs[('clath_aux+gak_new', 'test')]\n",
    "df['preds'] = dnn.predict(df[feat_names[:1]])\n",
    "df = df.sort_values(by='preds')\n",
    "x = df[feat_names[:1]]\n",
    "y = df['y_consec_thresh'].values\n",
    "preds = dnn.predict(x)\n",
    "n = df.shape[0]\n",
    "\n",
    "# sort things\n",
    "print(f'acc {np.mean((preds > 0) == y):0.3f} vs baseline {1-np.mean(y):0.2f}', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at different dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [03:13<00:00, 32.31s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"loading data\")\n",
    "dsets = ['clath_aux+gak_a7d2', 'clath_aux+gak', 'clath_aux+gak_a7d2_new', 'clath_aux+gak_new', 'clath_gak', 'clath_aux_dynamin'] # need to add dynamin\n",
    "splits = ['train', 'test']\n",
    "#feat_names = ['X_same_length_normalized'] + data.select_final_feats(data.get_feature_names(df))\n",
    "              #['mean_total_displacement', 'mean_square_displacement', 'lifetime']\n",
    "meta = ['cell_num', 'Y_sig_mean', 'Y_sig_mean_normalized', 'y_consec_thresh']\n",
    "dfs, feat_names = data.load_dfs_for_lstm(dsets=dsets, splits=splits, meta=meta, filter_short=False, normalize=False)\n",
    "\n",
    "# df_full = pd.concat([dfs[(k, s)]\n",
    "#                  for (k, s) in dfs\n",
    "#                  if s == 'train'])[feat_names + meta]\n",
    "# df_full = df_full.dropna()\n",
    "ds = {(k, v): dfs[(k, v)]\n",
    "      for (k, v) in sorted(dfs.keys(), key=lambda x: x[1] + x[0])\n",
    "      #if not k == 'clath_aux+gak_a7d2_new'\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**summarize dsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrr}\n",
      "\\toprule\n",
      "          &       &  Total clean tracks &  Difficult tracks &  Difficult valid events &  Short tracks &  Short valid events \\\\\n",
      "Dataset & Partition &                     &                   &                         &               &                     \\\\\n",
      "\\midrule\n",
      "clath\\_aux+gak & test &                1551 &               494 &                     264 &          1057 &                  96 \\\\\n",
      "          & train &                5783 &              1750 &                    1054 &          4033 &                 464 \\\\\n",
      "clath\\_aux+gak\\_a7d2 & test &                2448 &              1018 &                     439 &          1430 &                  73 \\\\\n",
      "          & train &                7245 &              2979 &                    1523 &          4266 &                 212 \\\\\n",
      "clath\\_aux+gak\\_a7d2\\_new & test &               16893 &              1495 &                     978 &         15398 &                2157 \\\\\n",
      "          & train &               49743 &              7029 &                    4900 &         42714 &                9591 \\\\\n",
      "clath\\_aux+gak\\_new & test &                4040 &               633 &                     211 &          3407 &                 183 \\\\\n",
      "          & train &               16250 &              2922 &                    1515 &         13328 &                1548 \\\\\n",
      "clath\\_aux\\_dynamin & test &               45061 &              8457 &                    2920 &         36604 &                2205 \\\\\n",
      "          & train &              102712 &             20617 &                    7050 &         82095 &                4977 \\\\\n",
      "clath\\_gak & test &                5189 &              1319 &                     628 &          3870 &                 378 \\\\\n",
      "          & train &               12938 &              3165 &                    1288 &          9773 &                 749 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vals = {} # key is dataset, Partition\n",
    "for k in sorted(ds, key=lambda kv: (kv[0], kv[1])):\n",
    "    d = ds[k]\n",
    "    d.short = d.lifetime <= 15\n",
    "    # print(k, d.lifetime.min())\n",
    "    y = d['y_consec_thresh']\n",
    "    feats = ['Total clean tracks',\n",
    "             'Difficult tracks', 'Difficult valid events', \n",
    "             'Short tracks', 'Short valid events',]\n",
    "    vals[k] = [d.shape[0],\n",
    "            (~d.short).sum(), y[~d.short].sum(),\n",
    "            d.short.sum(), y[d.short].sum()\n",
    "           ]\n",
    "    vals[k] = [int(x) for x in vals[k]]\n",
    "#     print(feats, vals)\n",
    "df = pd.DataFrame.from_dict(vals).transpose().round(decimals=0)\n",
    "df.columns = feats\n",
    "df.index = df.index.set_names(['Dataset', 'Partition'])\n",
    "print(df.to_latex(index=True, index_names=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate predictions on diff datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:16<00:00,  2.67s/it]\n"
     ]
    }
   ],
   "source": [
    "normalize_by_train = False\n",
    "exclude_easy_tracks = True\n",
    "orig_dset = 'clath_aux+gak_a7d2'\n",
    "\n",
    "# set up lists\n",
    "dsets = ['validation', 'test']\n",
    "ys_list = [y_full_cv, y_test]\n",
    "preds_list = [preds_cv, preds_test]\n",
    "preds_proba_list = [preds_proba_cv, preds_proba_test]\n",
    "Y_max_list = [df_cv['Y_max'], df_test['Y_max']]\n",
    "\n",
    "# loop over new datasets\n",
    "outcome_def = 'y_consec_thresh'\n",
    "# outcome_def = 'y_rule_based'\n",
    "dset_names = [k for k in config.DSETS.keys()\n",
    "              if not k == orig_dset\n",
    "              and not 'pi4p' in k]\n",
    "for dset_name in tqdm(dset_names):\n",
    "    _, y_new, preds_new, preds_proba_new, Y_maxes = analyze_helper.normalize_and_predict(m0, feat_names_selected, dset_name,\n",
    "                                                                                         normalize_by_train,\n",
    "                                                                                         exclude_easy_tracks=exclude_easy_tracks)\n",
    "    dsets.append(dset_name)\n",
    "    ys_list.append(deepcopy(y_new))\n",
    "    preds_list.append(deepcopy(preds_new))\n",
    "    preds_proba_list.append(deepcopy(preds_proba_new))\n",
    "    Y_max_list.append(Y_maxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**show metrics on different dsets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if exclude_easy_tracks, this is just for hard tracks\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Accuracy &  Roc auc &  Balanced accuracy \\\\\n",
      "\\midrule\n",
      "Validation        &      0.74 &     0.81 &               0.74 \\\\\n",
      "Test              &      0.73 &     0.80 &               0.73 \\\\\n",
      "Clath\\_aux+gak     &      0.75 &     0.81 &               0.75 \\\\\n",
      "Clath\\_aux+gak\\_new &      0.76 &     0.83 &               0.76 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def roundd(x):\n",
    "    try:\n",
    "        return x.round(2)\n",
    "    except:\n",
    "        return [y.round(2) for y in x]\n",
    "    \n",
    "def mean_diff(vals, preds):\n",
    "    return np.mean(vals[preds==1]) - np.mean(vals[preds==0])\n",
    "\n",
    "r_long = {}\n",
    "n = len(dsets)\n",
    "for s in train.scorers:\n",
    "    if s == 'roc_auc':\n",
    "        r_long[s] = [roundd(metrics.roc_auc_score(ys_list[i],\n",
    "                                                  preds_proba_list[i])) for i in range(n)]\n",
    "    elif 'curve' not in s and 'acc' in s:\n",
    "        r_long[s] = [roundd(train.scorers[s](ys_list[i], preds_list[i])) for i in range(n)]        \n",
    "r_long['diff_aux_max_by_class'] = [mean_diff(Y_max_list[i], preds_list[i]) for i in range(n)]\n",
    "r_long['aux+ ratio'] = [np.mean(ys_list[i]) for i in range(n)]\n",
    "\n",
    "print('if exclude_easy_tracks, this is just for hard tracks')\n",
    "r = pd.DataFrame.from_dict(r_long).transpose()\n",
    "r.columns = dsets\n",
    "r.round(2)\n",
    "\n",
    "# style results\n",
    "r = r[['validation', 'test', 'clath_aux+gak', 'clath_aux+gak_new']].round(2)\n",
    "r.columns = r.columns.map(str.capitalize)\n",
    "r = r.loc[['accuracy', 'roc_auc', 'balanced_accuracy']] # reorder rows\n",
    "r.index = r.index.map(str.capitalize)\n",
    "r.index = r.index.map(lambda s: str.replace(s, '_', ' '))\n",
    "r\n",
    "print(r.transpose().to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower res data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "DOWNSAMPLE_list = range(1, 11)\n",
    "for DOWNSAMPLE in tqdm(DOWNSAMPLE_list):\n",
    "\n",
    "    # downsample\n",
    "    df_cv = deepcopy(df[df.valid == 1]) # exclude test cells, short/long tracks, hotspots\n",
    "    df_cv['X'] = [x[::DOWNSAMPLE] for x in df_cv.X]\n",
    "    df_cv['X_extended'] = [x[::DOWNSAMPLE] for x in df_cv.X_extended]\n",
    "    df_cv['lifetime'] = [len(x) for x in df_cv.X]\n",
    "    df_cv = features.add_basic_features(df_cv)\n",
    "\n",
    "\n",
    "    # get data\n",
    "    X, y, norms = analyze_helper.normalize(df_cv, outcome_def)\n",
    "    d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_name, out_dir, df_cv.cell_num, X, y)\n",
    "    y_full_cv = df_cv[outcome_def].iloc[idxs_cv].values.astype(np.int)\n",
    "    preds = d_full_cv[model_name].values\n",
    "    preds_proba = d_full_cv[model_name + '_proba'].values\n",
    "    acc = np.mean(preds==y_full_cv)\n",
    "    accs.append(acc)\n",
    "#     print(f'downsampling rate {DOWNSAMPLE} acc {acc.round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(dpi=300)\n",
    "plt.plot(DOWNSAMPLE_list, accs, '.-', color=cb, lw=3, ms=18)\n",
    "plt.xlabel('Downsamping factor')\n",
    "plt.ylabel('Accuracy on difficult region')\n",
    "viz.savefig('downsampling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of example track\n",
    "track_num = 3\n",
    "ex = deepcopy(df[df.valid == 1]).iloc[track_num]\n",
    "viz.plot_example(ex)\n",
    "plt.plot(np.arange(len(ex.X))[::3], ex.X[::3], 'o', color='w', alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
