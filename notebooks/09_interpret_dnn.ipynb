{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('dark_background')\n",
    "import data\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch import NeuralNetRegressor\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import train_reg\n",
    "from math import floor\n",
    "from copy import deepcopy\n",
    "import config\n",
    "import models\n",
    "import pandas as pd\n",
    "import features\n",
    "from scipy.stats import skew, pearsonr\n",
    "import outcomes\n",
    "import neural_networks\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import acd\n",
    "from acd.scores import cd_propagate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.68s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# currently trained only on 'clath_aux+gak_a7d2_new'\n",
    "dsets = ['clath_aux+gak_new']\n",
    "splits = ['test']\n",
    "#feat_names = ['X_same_length_normalized'] + data.select_final_feats(data.get_feature_names(df))\n",
    "              #['mean_total_displacement', 'mean_square_displacement', 'lifetime']\n",
    "meta = ['cell_num', 'Y_sig_mean', 'Y_sig_mean_normalized']\n",
    "dfs = {}\n",
    "for dset in tqdm(dsets):\n",
    "    for split in splits:\n",
    "        df = data.get_data(dset=dset)\n",
    "        df = df[~(df.short | df.long | df.hotspots)]\n",
    "#         df = df[df.valid]\n",
    "        df = df[df.lifetime > 15] # only keep hard tracks\n",
    "        df = df[df.cell_num.isin(config.DSETS[dset][split])] # exclude held-out test data\n",
    "        feat_names = ['X_same_length_normalized'] + data.select_final_feats(data.get_feature_names(df))\n",
    "\n",
    "        # downsample tracks\n",
    "        length = 40\n",
    "        df['X_same_length'] = [features.downsample(df.iloc[i]['X'], length)\n",
    "                               for i in range(len(df))] # downsampling\n",
    "        # normalize tracks\n",
    "        df = features.normalize_track(df, track='X_same_length', by_time_point=False)\n",
    "\n",
    "        # regression response\n",
    "        df = train_reg.add_sig_mean(df)     \n",
    "\n",
    "        # remove extraneous feats\n",
    "        # df = df[feat_names + meta]\n",
    "#         df = df.dropna() \n",
    "\n",
    "        # normalize features\n",
    "        for feat in feat_names:\n",
    "            if 'X_same_length' not in feat:\n",
    "                df = features.normalize_feature(df, feat)\n",
    "\n",
    "        dfs[(dset, split)] = deepcopy(df)\n",
    "\n",
    "# load model\n",
    "results = pkl.load(open('../models/dnn_full_long_normalized_across_track_4_feats.pkl', 'rb'))\n",
    "# results = pkl.load(open('../models/clath_aux+gak_a7d2_new_Y_sig_mean_normalized_nn_lstm_100_40.pkl', 'rb'))\n",
    "dnn = neural_networks.neural_net_sklearn(D_in=40, H=40, p=3, arch='lstm')\n",
    "dnn.model.load_state_dict(results['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dfs[('clath_aux+gak_a7d2', 'train')]\n",
    "df = dfs[('clath_aux+gak_new', 'test')]\n",
    "X = df[feat_names]\n",
    "y = df['y_consec_thresh']\n",
    "acc_orig = np.mean((dnn.predict(X) > 0) == y)\n",
    "np.random.seed(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imps = {feat_name: [] for feat_name in feat_names}\n",
    "reps = 3\n",
    "for feat_name in tqdm(feat_names):\n",
    "    for r in range(reps):\n",
    "        X_copy = deepcopy(X)\n",
    "        X_copy[feat_name] = np.random.permutation(X_copy[feat_name].values)\n",
    "        acc = np.mean((dnn.predict(X_copy) > 0) == y)\n",
    "        imps[feat_name].append(acc_orig - acc)\n",
    "100 * pd.DataFrame.from_dict(imps).mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cd_score(xtrack_t, xfeats_t, start, stop, model):\n",
    "    \n",
    "    mask = torch.zeros(xfeats_t.shape)\n",
    "    #mask[start: stop] = 1\n",
    "    #mask[: ,0:3] = 1\n",
    "    mask = 1\n",
    "    rel_feats = mask * xfeats_t\n",
    "    irrel_feats = xfeats_t - rel_feats\n",
    "    with torch.no_grad():\n",
    "        rel, irrel = cd_propagate.propagate_lstm(xtrack_t.unsqueeze(-1), dnn.model.lstm, start=start, stop=stop, my_device='cpu')\n",
    "    rel = rel.squeeze(1)\n",
    "    irrel = irrel.squeeze(1)\n",
    "    h_rel = torch.cat((rel, rel_feats), 1)\n",
    "    h_irrel = torch.cat((irrel, irrel_feats), 1)\n",
    "    rel, irrel = cd_propagate.propagate_conv_linear(h_rel, h_irrel, dnn.model.fc)\n",
    "    #return rel.item()\n",
    "    return rel.data.numpy()\n",
    "\n",
    "def plot_segs(track_segs, cd_scores, xtrack, pred, y):\n",
    "    cm = sns.diverging_palette(22, 220, as_cmap=True, center='light')\n",
    "    vabs = np.max(np.abs(cd_scores))\n",
    "    # plt.plot(xtrack, zorder=0, lw=2, color='#111111')\n",
    "    for i in range(len(track_segs)):\n",
    "        (s, e) = track_segs[i]\n",
    "        cd_score = cd_scores[i]\n",
    "        seq_len = e - s\n",
    "        xs = np.arange(s, e)\n",
    "        norm = matplotlib.colors.Normalize(vmin=-vabs, vmax=vabs)\n",
    "        if seq_len > 1:\n",
    "            cd_score = [cd_score] * seq_len\n",
    "            plt.plot(xs, xtrack[s: e], zorder=0, lw=2, color=cm(norm(cd_score[0])), alpha=0.5)\n",
    "        plt.scatter(xs, xtrack[s: e],\n",
    "                    c=cd_score, cmap=cm, vmin=-vabs, vmax=vabs, s=6)\n",
    "    plt.title(f\"Pred: {pred: .1f}, y: {y}\")\n",
    "    plt.colorbar(label='CD Score')\n",
    "    \n",
    "def max_abs_sum_seg(scores_list):\n",
    "    \n",
    "    n = len(scores_list[0])\n",
    "    res = [0]*n\n",
    "    paths = {}\n",
    "    res[0] = abs(scores_list[0][0])\n",
    "    paths[0] = [0]\n",
    "    for i in (range(1, n)):\n",
    "        cand = [res[j] + abs(scores_list[j+1][i]) for j in range(i)]\n",
    "        seg_start = np.argmax(cand)\n",
    "        res[i] = max(cand)\n",
    "        paths[i] = paths[seg_start] + [seg_start+1]\n",
    "    return res, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_name = 'X_same_length_normalized'\n",
    "track_name_unnormalized = 'X_same_length'\n",
    "df = dfs[('clath_aux+gak_new', 'test')]\n",
    "x = df[feat_names[0:4]]\n",
    "y = df['y_consec_thresh']\n",
    "m = 40\n",
    "xtrack_unnormalized = df[track_name_unnormalized]\n",
    "xtrack = x[track_name]\n",
    "xtrack_t = torch.tensor(np.array(list(xtrack.values)), dtype=torch.float)\n",
    "xfeats = x[[c for c in x.columns if c != track_name]]\n",
    "xfeats_t = torch.tensor(np.array(xfeats).astype(float), dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [09:31<00:00, 14.28s/it]\n"
     ]
    }
   ],
   "source": [
    "all_cd_scores = {}\n",
    "for s in tqdm(range(m)):\n",
    "    for e in range(s+1, m):\n",
    "        all_cd_scores[(s, e)] = calc_cd_score(xtrack_t, xfeats_t, s, e, dnn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-23cbccb7bab8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mcd_scores_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_cd_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_abs_sum_seg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd_scores_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrack_name_unnormalized\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 40)"
     ]
    }
   ],
   "source": [
    "all_res = []\n",
    "for i in range(len(X)):\n",
    "    cd_scores_list = np.zeros((m, m))\n",
    "    for s in (range(m)):\n",
    "        for e in range(s + 1, m + 1):            \n",
    "            cd_scores_list[s][e-1] = all_cd_scores[(s, e)][i]\n",
    "    res, paths = max_abs_sum_seg(cd_scores_list)\n",
    "    lt = np.sum(np.array(df[track_name_unnormalized].values[i]) != 0)\n",
    "    #all_res.append(paths[lt-1])\n",
    "    all_res.append(paths[m - 1])\n",
    "    #print(res[lt-1], paths[lt-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, R = 5, 10\n",
    "plt.figure(dpi=100, figsize=(4 * C, 3 * R))\n",
    "for i in range(50, 100):\n",
    "    ax = plt.subplot(R, C, i - 50 + 1)\n",
    "    segs = [(all_res[i][j], all_res[i][j+1]) for j in range(len(all_res[i])-1)] + [(all_res[i][-1], 40)]\n",
    "    scores = [all_cd_scores7[(s, e)][i][0] for (s, e) in segs]\n",
    "    plot_segs(track_segs=segs, cd_scores=scores, xtrack=xtrack_unnormalized.iloc[i],\n",
    "              pred=dnn.predict(X)[i],\n",
    "              y=y.values[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'results/all_cd_scores_clath_aux+gak_new_test.pkl', 'wb') as handle:\n",
    "    pkl.dump(all_cd_scores, handle, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cd_scores_normalized = {}\n",
    "for s in tqdm(range(m)):\n",
    "    for e in range(s + 1, m + 1):\n",
    "        x = all_cd_scores[(s, e)]\n",
    "        x = x.reshape(1, -1)[0]\n",
    "        all_cd_scores_normalized[(s, e)] = np.abs((x - np.mean(x))/np.std(x))\n",
    "        \n",
    "for i in range(len(df)):\n",
    "    cd_scores_list = np.zeros((m, m))\n",
    "    s0, e0 = 0, 0\n",
    "    m = 0\n",
    "    lt = np.sum(np.array(df[track_name_unnormalized].values[i]) != 0)\n",
    "    for s in (range(lt)):\n",
    "        for e in range(s+1, lt):            \n",
    "            cd_scores_list[s][e-1] = all_cd_scores_normalized[(s, e)][i]\n",
    "            if cd_scores_list[s][e-1] > m:\n",
    "                m = cd_scores_list[s][e-1]\n",
    "                s0, e0 = s, e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interpret one pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cd_score(start, stop, model):\n",
    "    mask = torch.zeros(xfeats_t.shape)\n",
    "    mask[start: stop] = 1\n",
    "    rel_feats = mask * xfeats_t\n",
    "    irrel_feats = xfeats_t - rel_feats\n",
    "    with torch.no_grad():\n",
    "        rel, irrel = cd_propagate.propagate_lstm(xtrack_t.unsqueeze(-1), dnn.model.lstm, start=start, stop=stop, my_device='cpu')\n",
    "    rel = rel.squeeze(1)\n",
    "    irrel = irrel.squeeze(1)\n",
    "    h_rel = torch.cat((rel, rel_feats), 1)\n",
    "    h_irrel = torch.cat((irrel, irrel_feats), 1)\n",
    "    rel, irrel = cd_propagate.propagate_conv_linear(h_rel, h_irrel, dnn.model.fc)\n",
    "    #return rel.item()\n",
    "    return rel.data.numpy()\n",
    "\n",
    "def plot_segs(track_segs, cd_scores, xtrack, pred):\n",
    "    cm = sns.diverging_palette(22, 220, as_cmap=True, center='light')\n",
    "    vabs = np.max(np.abs(cd_scores))\n",
    "    # plt.plot(xtrack, zorder=0, lw=2, color='#111111')\n",
    "    for i in range(len(track_segs)):\n",
    "        (s, e) = track_segs[i]\n",
    "        cd_score = cd_scores[i]\n",
    "        seq_len = e - s\n",
    "        xs = np.arange(s, e)\n",
    "        norm = matplotlib.colors.Normalize(vmin=-vabs, vmax=vabs)\n",
    "        if seq_len > 1:\n",
    "            cd_score = [cd_score] * seq_len\n",
    "            plt.plot(xs, xtrack[s: e], zorder=0, lw=2, color=cm(norm(cd_score[0])), alpha=0.5)\n",
    "        plt.scatter(xs, xtrack[s: e],\n",
    "                    c=cd_score, cmap=cm, vmin=-vabs, vmax=vabs, s=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_name = 'X_same_length_normalized'\n",
    "track_name_unnormalized = 'X_same_length'\n",
    "num = 100\n",
    "x = X.iloc[num: num + 1]\n",
    "xtrack_unnormalized = df.iloc[num: num + 1][track_name_unnormalized]\n",
    "xtrack = x[track_name]\n",
    "xtrack_t = torch.tensor(np.array(list(xtrack.values)), dtype=torch.float)\n",
    "xfeats = x[[c for c in x.columns if c != track_name]]\n",
    "xfeats_t = torch.tensor(np.array(xfeats).astype(float), dtype=torch.float)\n",
    "#pred = dnn.model(xtrack_t, xfeats_t).item()\n",
    "#print(f'pred {pred:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "T = 40 # seq len\n",
    "# track_segs = [(s, s + 1) for s in range(T)]\n",
    "DIV = 40\n",
    "track_segs_fourty = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "\n",
    "DIV = 20\n",
    "track_segs_twenty = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "DIV = 10\n",
    "track_segs_tenths = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "DIV = 6\n",
    "track_segs_fifths = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "DIV = 4\n",
    "track_segs_quarters = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "DIV = 1\n",
    "track_segs_full = [(floor(s * T / DIV), floor((s+1) * T / DIV))\n",
    "                    for s in range(DIV)]\n",
    "track_segs_list = [track_segs_fourty, track_segs_twenty, track_segs_tenths,\n",
    "                   track_segs_fifths, track_segs_quarters, track_segs_full]\n",
    "cd_scores_list = [[calc_cd_score(s, e, dnn.model)\n",
    "                  for (s, e) in track_segs]\n",
    "                  for track_segs in tqdm(track_segs_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200, figsize=(12, 6))\n",
    "R, C = 2, 3\n",
    "for i, track_segs in enumerate(track_segs_list):\n",
    "    ax = plt.subplot(R, C, i + 1)\n",
    "    cd_scores = cd_scores_list[i]\n",
    "    plot_segs(track_segs, cd_scores, xtrack_unnormalized.iloc[0], pred)\n",
    "    \n",
    "    if i == C * (R - 1):\n",
    "        plt.xlabel('Time')\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "    if i == 0:\n",
    "        plt.ylabel('Clath Amplitude')\n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    if i  == C - 1:\n",
    "        plt.colorbar(label='CD Score')\n",
    "    else:\n",
    "        plt.colorbar()\n",
    "    if i ==  C * R - 1:\n",
    "        plt.text(0.6, 0.9,\n",
    "                 f'Pred: {pred:.2f}', fontsize='x-large', transform = ax.transAxes)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from trim.trim import TrimModel\n",
    "from functools import partial\n",
    "\n",
    "# setup a trim model\n",
    "model = dnn.model\n",
    "transform = partial(torch.rfft, signal_ndim=1, onesided=False) # fft\n",
    "inv_transform = partial(torch.irfft, signal_ndim=1, onesided=False) # inverse fft\n",
    "model_trim = TrimModel(model=model, inv_transform=inv_transform) # trim model\n",
    "\n",
    "# get a data point\n",
    "x = torch.randn(1, 10)\n",
    "s = transform(x)\n",
    "\n",
    "# can now use any attribution method on the trim model\n",
    "# get (input_x_gradient) attribution in the fft space\n",
    "s.requires_grad = True\n",
    "model_trim(s).backward()\n",
    "input_x_gradient = s.grad * s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
