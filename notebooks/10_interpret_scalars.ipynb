{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.style.use('dark_background')\n",
    "import full_data_reg\n",
    "import data\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch import NeuralNetRegressor\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "import pickle as pkl\n",
    "import train_reg\n",
    "from math import floor\n",
    "from copy import deepcopy\n",
    "import config\n",
    "import models\n",
    "import pandas as pd\n",
    "import features\n",
    "from scipy.stats import skew, pearsonr\n",
    "import outcomes\n",
    "import neural_networks\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "import acd\n",
    "from acd.scores import cd_propagate\n",
    "import lime, shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-68de5a1c6176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y_sig_mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Y_sig_mean_normalized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mdset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "# currently trained only on 'clath_aux+gak_a7d2_new'\n",
    "dsets = ['clath_aux+gak_new']\n",
    "splits = ['test']\n",
    "#feat_names = ['X_same_length_normalized'] + data.select_final_feats(data.get_feature_names(df))\n",
    "              #['mean_total_displacement', 'mean_square_displacement', 'lifetime']\n",
    "meta = ['cell_num', 'Y_sig_mean', 'Y_sig_mean_normalized']\n",
    "dfs = {}\n",
    "for dset in tqdm(dsets):\n",
    "    for split in splits:\n",
    "        df = data.get_data(dset=dset)\n",
    "        df = df[~(df.short | df.long | df.hotspots)]\n",
    "#         df = df[df.valid]\n",
    "        df = df[df.lifetime > 15] # only keep hard tracks\n",
    "        df = df[df.cell_num.isin(config.DSETS[dset][split])] # exclude held-out test data\n",
    "        feat_names = ['X_same_length_normalized'] + data.select_final_feats(data.get_feature_names(df))\n",
    "\n",
    "        # downsample tracks\n",
    "        length = 40\n",
    "        df['X_same_length'] = [features.downsample(df.iloc[i]['X'], length)\n",
    "                               for i in range(len(df))] # downsampling\n",
    "        # normalize tracks\n",
    "        df = features.normalize_track(df, track='X_same_length', by_time_point=False)\n",
    "\n",
    "        # regression response\n",
    "        df = train_reg.add_sig_mean(df)     \n",
    "\n",
    "        # remove extraneous feats\n",
    "        # df = df[feat_names + meta]\n",
    "#         df = df.dropna() \n",
    "\n",
    "        # normalize features\n",
    "        for feat in feat_names:\n",
    "            if 'X_same_length' not in feat:\n",
    "                df = features.normalize_feature(df, feat)\n",
    "\n",
    "        dfs[(dset, split)] = deepcopy(df)\n",
    "\n",
    "# load model\n",
    "# results = pkl.load(open('../models/dnn_full_long_normalized_across_track_4_feats.pkl', 'rb'))\n",
    "# dnn = neural_networks.neural_net_sklearn(D_in=40, H=40, p=3, arch='lstm')\n",
    "results = pkl.load(open('../models/clath_aux+gak_a7d2_new_Y_sig_mean_normalized_nn_lstm_100_40.pkl', 'rb'))\n",
    "dnn = neural_networks.neural_net_sklearn(D_in=40, H=40, p=17, arch='lstm')\n",
    "dnn.model.load_state_dict(results['model_state_dict'])"
   ]
  },
  {
   "source": [
    "# prepare for interp"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dfs[('clath_aux+gak_a7d2', 'train')]\n",
    "df = dfs[('clath_aux+gak_new', 'test')]\n",
    "X = df[feat_names]\n",
    "y = df['y_consec_thresh']\n"
   ]
  },
  {
   "source": [
    "# interpret shifts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdsklj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_explanation = explainer.explain_instance(x, m.predict_proba, num_features=x.size) #, top_labels=1)\n",
    "# lime_explanation.show_in_notebook(show_table=True)\n",
    "# lime_explanation.as_list() # give more info on fitted lime values\n",
    "lime_values = [l[1] for l in lime_explanation.as_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# global feat imp"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_importance(X, model, feat_names):\n",
    "    '''custom bc some features are lists (e.g. the track)'''\n",
    "    acc_orig = np.mean((dnn.predict(X) > 0) == y)\n",
    "    imps = {feat_name: [] for feat_name in feat_names}\n",
    "    reps = 3\n",
    "    for feat_name in tqdm(feat_names):\n",
    "        for r in range(reps):\n",
    "            X_copy = deepcopy(X)\n",
    "            X_copy[feat_name] = np.random.permutation(X_copy[feat_name].values)\n",
    "            acc = np.mean((dnn.predict(X_copy) > 0) == y)\n",
    "            imps[feat_name].append(acc_orig - acc)\n",
    "    return pd.DataFrame.from_dict(imps).mean().sort_values(ascending=False)\n",
    "\n",
    "np.random.seed(13)\n",
    "imps = perm_importance(X, dnn, feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}