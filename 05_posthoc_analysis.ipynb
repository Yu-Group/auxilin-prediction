{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "using model mlp2_25_None=3_ros=1.2_h=-1\n",
      "\t0.724 mlp2_25_None=3_ros=1.2_h=-1\n",
      "\t0.722 svm_25_None=3_ros=1.2_h=0\n",
      "\t0.721 svm_25_None=3_ros=1.2_h=-1\n",
      "\t0.721 mlp2_16_None=3_ros=1_h=-1\n",
      "\t0.720 mlp2_16_None=3_ros=1.2_h=-1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join as oj\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "plt.style.use('dark_background')\n",
    "import mat4py\n",
    "import pandas as pd\n",
    "import data\n",
    "import models\n",
    "from matplotlib_venn import venn3, venn2\n",
    "from sklearn.model_selection import KFold\n",
    "from colorama import Fore\n",
    "import pickle as pkl\n",
    "import viz\n",
    "from style import *\n",
    "import analyze_helper\n",
    "import train\n",
    "from sklearn import decomposition\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "outcome_def = 'y_consec_thresh'\n",
    "out_dir = oj('/scratch/users/vision/abc', 'mar5_1')\n",
    "results = analyze_helper.load_results(out_dir)\n",
    "\n",
    "df = data.get_data()\n",
    "n = df.shape[0]\n",
    "X, y, norms = analyze_helper.normalize(df, outcome_def)\n",
    "\n",
    "# look at best models\n",
    "r = results\n",
    "r = r.sort_values('accuracy', ascending=False)\n",
    "idx = np.array(r.index)\n",
    "accs = np.array(r.accuracy)\n",
    "model_name = idx[0]\n",
    "# model_name = 'svm_16_ros=1.2_select_rf=3'\n",
    "print('using model', model_name)\n",
    "for i in range(5):\n",
    "    print(f'\\t{accs[i]:.3f}', idx[i])\n",
    "\n",
    "\n",
    "\n",
    "d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_name, out_dir, df.cell_num, X, y)\n",
    "y_full_cv = df[outcome_def].iloc[idxs_cv].values.astype(np.int)\n",
    "preds = d_full_cv[model_name].values\n",
    "preds_proba = d_full_cv[model_name + '_proba'].values\n",
    "\n",
    "results_individual = pkl.load(open(oj(out_dir, f'{model_name}.pkl'), 'rb'))\n",
    "assert np.sum(idxs_cv == np.arange(idxs_cv.size)) == idxs_cv.size, \\\n",
    "       'points not in same order'\n",
    "assert np.mean(preds==y_full_cv) == np.average(results_individual['cv']['accuracy'], \n",
    "                                               weights=results_individual['num_pts_by_fold_cv']), \\\n",
    "        'did not properly load model/data'\n",
    "tp, tn, fp, fn = analyze_helper.calc_errs(preds, y_full_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the biggest errors\n",
    "num_to_plot = 16\n",
    "\n",
    "print('total pts', preds.shape[0])\n",
    "# for idxs, name in zip([fp, fn, tp, tn], ['fp', 'fn', 'tp', 'tn']):\n",
    "# for idxs, name in zip([fp, fn], ['fp', 'fn']):\n",
    "for idxs, name in zip([tp, tn], ['tp', 'tn']):\n",
    "    print(name, idxs.sum(), idxs.sum() / preds.shape[0])\n",
    "    inds = viz.viz_biggest_errs(df, idxs_cv, idxs, y_full_cv, preds, preds_proba, num_to_plot)\n",
    "#     plt.savefig(f'{name}.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize errs 1d\n",
    "key = 'X_max' # lifetime, X_min, fall, X_max\n",
    "viz.viz_errs_1d(X.iloc[idxs_cv], preds, preds_proba, y_full_cv, norms, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize errs 2d\n",
    "key1 = 'fall' # fall, x_pos, pc1\n",
    "key2 = 'X_mean' # X_min, y_pos, pc2\n",
    "viz.viz_errs_2d(df, idxs_cv, preds, y_full_cv, key1=key1, key2=key2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of when things are peaking based on errs\n",
    "dist_to_end = df.iloc[idxs_fp]['lifetime'] - df.iloc[idxs_fp]['Y_peak_idx'] - 1\n",
    "frac_to_end = 1 - df.iloc[idxs_fp]['Y_peak_idx'] / df.iloc[idxs_fp]['lifetime']\n",
    "print(np.unique(dist_to_end, return_counts=True))\n",
    "plt.hist(frac_to_end, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading + preprocessing data...\n",
      "\tloading tracks...\n",
      "\tpreprocessing data...\n",
      "\tadding features...\n",
      "hotspots acc:\t\t\t0.6995884773662552\n"
     ]
    }
   ],
   "source": [
    "# calculate acc for hotspots\n",
    "results_individual = pkl.load(open(oj(out_dir, f'{model_name}.pkl'), 'rb'))\n",
    "df = data.get_data(use_processed=False, remove_hotspots=False, save_processed=False)\n",
    "df = df[df['hotspots']==1]\n",
    "X, y, norms = normalize(df)\n",
    "\n",
    "preds, pred_proba = analyze_helper.analyze_individual_results(results_individual, \n",
    "                                               X, y, print_results=False, \n",
    "                                               plot_results=False, model_cv_fold=1)\n",
    "print(f'hotspots acc:\\t\\t\\t{np.mean(preds==df[outcome_def])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inter-cell accs [0.71 0.73 0.69 0.69 0.69]\n"
     ]
    }
   ],
   "source": [
    "print('accuracy across cells', np.array(results_individual['cv']['accuracy']).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viz feature relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint histograms of two features (colored by outcome)\n",
    "viz.jointplot_grouped('fall', 'slope_end', 'y_consec_sig', df, scatter_alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint histogram, colored by predicted prob\n",
    "print(results_individual['feat_names_selected'])\n",
    "d = df.iloc[idxs_cv]\n",
    "d['preds'] = preds\n",
    "d['preds_proba'] = preds_proba\n",
    "key1 = 'fall'\n",
    "key2 = 'slope_end'\n",
    "plt.figure(dpi=300)\n",
    "plt.scatter(d[key1], d[key2], c=d['preds_proba'], alpha=0.5)\n",
    "plt.xlabel(key1)\n",
    "plt.ylabel(key2)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('predicted prob.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viz boundaries / outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = results_individual['imps']['model'][0]    \n",
    "# viz.plot_decision_boundary('X_std', 'fall', m, df, norms, num_pts=df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize outliers in venn-diagram\n",
    "viz.viz_errs_outliers_venn(X.iloc[idxs_cv], preds, y_full_cv, num_feats_reduced=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration curve\n",
    "plt.figure(dpi=200)\n",
    "prob_true, prob_pred = calibration_curve(y_full_cv, preds_proba, \n",
    "                                         normalize=False, n_bins=10, strategy='quantile')\n",
    "plt.plot(prob_true, prob_pred, '.-')\n",
    "plt.plot([0, 1], [0, 1], alpha=0.3, color='gray')\n",
    "plt.xlabel('true prob')\n",
    "plt.ylabel('predicted prob')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform pca\n",
    "pca = decomposition.PCA(whiten=True)\n",
    "pca.fit(X.iloc[idxs_cv])\n",
    "viz.plot_pcs(pca, X.iloc[idxs_cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=2, whiten=True)\n",
    "X_reduced = pca.fit_transform(X.iloc[idxs_cv])\n",
    "plt.figure(dpi=200)\n",
    "ys_neg = y[idxs_cv] == 0\n",
    "plt.plot(X_reduced[:, 0][ys_neg], X_reduced[:, 1][ys_neg], 'o', \n",
    "         color=cr, alpha=0.3, markeredgewidth=0, ms=2)\n",
    "plt.plot(X_reduced[:, 0][~ys_neg], X_reduced[:, 1][~ys_neg], 'o', \n",
    "         color=cb, alpha=0.3, markeredgewidth=0, ms=2)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_feat_names = ['X_max',\n",
    "                #'y_consec_sig', \n",
    "                'y_conservative_thresh', \n",
    "                'Y_peak_time_frac',\n",
    "                'Y_max',\n",
    "                'y_z_score',\n",
    "                'X_max_diff'\n",
    "                ]\n",
    "pca = PCA(n_components=2)\n",
    "df_train = df[df.cell_num.isin([1, 2, 3, 4, 5])]\n",
    "df_train['y_cv'] = preds\n",
    "df_no_consec = df_train[df_train.y_consec_sig == False]\n",
    "df_X = df_no_consec[Y_feat_names]\n",
    "df_X = (df_X - df_X.mean()) / df_X.std()\n",
    "#X_new = X_new[np.where(df.y_consec_sig == False)[0],:]\n",
    "X_new = pca.fit_transform(df_X)\n",
    "#fig, ax = plt.subplots()\n",
    "tn = np.where((df_no_consec[outcome_def] == 0) & (df_no_consec['y_cv'] == 0))[0]\n",
    "tp = np.where((df_no_consec[outcome_def] == 1) & (df_no_consec['y_cv'] == 1))[0]\n",
    "fn = np.where((df_no_consec[outcome_def] == 1) & (df_no_consec['y_cv'] == 0))[0]\n",
    "fp = np.where((df_no_consec[outcome_def] == 0) & (df_no_consec['y_cv'] == 1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at many models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['mlp2_11_none', 'svm_35_none', 'logistic_4_none', 'rf_9_none']\n",
    "# model_names = ['mlp2_11_none', 'mlp2_9_none', 'mlp2_4_none']\n",
    "model_names = idx[:3]\n",
    "d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_names, out_dir, df.cell_num, X, y)\n",
    "y_full_cv = df[outcome_def].iloc[idxs_cv].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced_accuracy 0.7042086967746695\n",
      "accuracy 0.7206502107164359\n",
      "precision 0.7748538011695907\n",
      "recall 0.7733463035019456\n",
      "f1 0.7740993184031157\n",
      "roc_auc 0.7042086967746695\n",
      "precision_recall_curve (array([0.61890427, 0.7748538 , 1.        ]), array([1.       , 0.7733463, 0.       ]), array([False,  True]))\n",
      "roc_curve (array([0.        , 0.36492891, 1.        ]), array([0.       , 0.7733463, 1.       ]), array([2, 1, 0]))\n"
     ]
    }
   ],
   "source": [
    "# ensemble\n",
    "d_full_cv_probs = d_full_cv[[k for k in d_full_cv.keys() if 'proba' in k]]\n",
    "preds_soft = d_full_cv_probs.sum(axis=1) / d_full_cv_probs.shape[1]\n",
    "\n",
    "for score_name in train.scorers.keys():\n",
    "    print(score_name, train.scorers[score_name](y_full_cv, preds_soft > 0.5))\n",
    "# metrics.accuracy_score(y_ensemble, preds_soft>0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**venn-diagram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = []\n",
    "for model_name in model_names:\n",
    "    args = np.argwhere(d_full_cv[model_name] != y_full_cv)\n",
    "    sets.append(set(args.flatten().tolist()))\n",
    "    \n",
    "plt.figure(dpi=300)\n",
    "plt.title('venn diagram of shared errors')\n",
    "venn3(sets, model_names[:3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.get_data()\n",
    "n = df.shape[0]\n",
    "X, y, norms = analyze_helper.normalize(df, outcome_def)\n",
    "idxs_test = df.cell_num.isin([data.cell_nums_test])\n",
    "X_test, Y_test = X[idxs_test], y[idxs_test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
