{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "using model svm_16_None=3_ros=1_h=1_cal=True\n",
      "\t0.760 svm_16_None=3_ros=1_h=1_cal=True\n",
      "\t0.758 mlp2_16_None=3_ros=1.2_h=0_cal=True\n",
      "\t0.757 svm_16_None=3_ros=1_h=0_cal=True\n",
      "\t0.756 svm_16_None=3_ros=1.2_h=1_cal=True\n",
      "\t0.756 mlp2_16_None=3_ros=1_h=-1_cal=True\n",
      "succesfully loaded!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join as oj\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "plt.style.use('dark_background')\n",
    "import data\n",
    "from matplotlib_venn import venn3, venn2\n",
    "import pickle as pkl\n",
    "import viz\n",
    "from style import *\n",
    "import analyze_helper\n",
    "from sklearn import decomposition\n",
    "from sklearn.calibration import calibration_curve\n",
    "import config\n",
    "import train \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "outcome_def = 'y_consec_thresh'\n",
    "out_dir = oj('/scratch/users/vision/abc', 'apr28_1') # mar7_2 is 0.95, mar8_1 is 0.96\n",
    "results = analyze_helper.load_results(out_dir)\n",
    "\n",
    "# get data\n",
    "df = data.get_data()\n",
    "n = df.shape[0]\n",
    "df_cv = df[df.valid == 1] # exclude test cells, short/long tracks, hotspots\n",
    "X, y, norms = analyze_helper.normalize(df_cv, outcome_def)\n",
    "\n",
    "# select model\n",
    "r = results\n",
    "r = r.sort_values('accuracy', ascending=False)\n",
    "idx = np.array(r.index)\n",
    "accs = np.array(r.accuracy)\n",
    "model_name = idx[0]\n",
    "# model_name = 'svm_16_ros=1.2_select_rf=3'\n",
    "print('using model', model_name)\n",
    "for i in range(5):\n",
    "    print(f'\\t{accs[i]:.3f}', idx[i])\n",
    "    \n",
    "\n",
    "# load model + preds\n",
    "d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_name, out_dir, df_cv.cell_num, X, y)\n",
    "y_full_cv = df_cv[outcome_def].iloc[idxs_cv].values.astype(np.int)\n",
    "preds_cv = d_full_cv[model_name].values\n",
    "preds_proba_cv = d_full_cv[model_name + '_proba'].values\n",
    "\n",
    "results_individual = pkl.load(open(oj(out_dir, f'{model_name}.pkl'), 'rb'))\n",
    "assert np.sum(idxs_cv == np.arange(idxs_cv.size)) == idxs_cv.size, \\\n",
    "       'points not in same order'\n",
    "assert np.mean(preds_cv==y_full_cv) == np.average(results_individual['cv']['accuracy'], \n",
    "                                               weights=results_individual['num_pts_by_fold_cv']), \\\n",
    "        'did not properly load model/data'\n",
    "tp, tn, fp, fn = analyze_helper.calc_errs(preds_cv, y_full_cv)\n",
    "print('succesfully loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lower res data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data at lower res**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:28<00:00,  3.66s/it]\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "DOWNSAMPLE_list = [1, 2, 3, 4, 5, 10, 20]\n",
    "for DOWNSAMPLE in tqdm(DOWNSAMPLE_list):\n",
    "\n",
    "\n",
    "    # downsample\n",
    "    df_cv = deepcopy(df[df.valid == 1]) # exclude test cells, short/long tracks, hotspots\n",
    "    df_cv['X'] = [x[::DOWNSAMPLE] for x in df_cv.X]\n",
    "    df_cv['X_extended'] = [x[::DOWNSAMPLE] for x in df_cv.X_extended]\n",
    "    df_cv['lifetime'] = [len(x) for x in df_cv.X]\n",
    "    df_cv = data.add_features(df_cv)\n",
    "\n",
    "\n",
    "    # get data\n",
    "    X, y, norms = analyze_helper.normalize(df_cv, outcome_def)\n",
    "    d_full_cv, idxs_cv = analyze_helper.get_data_over_folds(model_name, out_dir, df_cv.cell_num, X, y)\n",
    "    y_full_cv = df_cv[outcome_def].iloc[idxs_cv].values.astype(np.int)\n",
    "    preds = d_full_cv[model_name].values\n",
    "    preds_proba = d_full_cv[model_name + '_proba'].values\n",
    "    acc = np.mean(preds==y_full_cv)\n",
    "    accs.append(acc)\n",
    "#     print(f'downsampling rate {DOWNSAMPLE} acc {acc.round(3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "plt.plot(DOWNSAMPLE_list, accs, '.-', color=cb)\n",
    "plt.xlabel('downsampling factor')\n",
    "plt.ylabel('hard acc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_num = 3\n",
    "ex = deepcopy(df[df.valid == 1]).iloc[track_num]\n",
    "# print(ex)\n",
    "viz.plot_example(ex)\n",
    "plt.plot(np.arange(len(ex.X))[::3], ex.X[::3], 'o', color='w', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CELLS_TRAIN = config.SPLITS['orig']['train']\n",
    "df_train = df[df.cell_num.isin(CELLS_TRAIN)]\n",
    "X_train = df_train[data.get_feature_names(df_train)]\n",
    "X_mean_train = X_train.mean()\n",
    "X_std_train = X_train.std()\n",
    "\n",
    "CELLS_TEST = config.SPLITS['orig']['test']\n",
    "df_test = df[df.cell_num.isin(CELLS_TEST)]\n",
    "X_test = df_test[data.get_feature_names(df_test)]\n",
    "X_test = (X_test - X_mean_train) / X_std_train\n",
    "y_test = df_test[outcome_def].values\n",
    "\n",
    "df_new = data.get_data(dset='clath_aux', use_processed=True,\n",
    "                   use_processed_dicts=True, outcome_def=outcome_def,\n",
    "                   previous_meta_file='processed/metadata_orig.pkl')\n",
    "X_new = df_new[data.get_feature_names(df_new)]\n",
    "X_new = (X_new - X_mean_train) / X_std_train\n",
    "y_new = df_new[outcome_def].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = results_individual['imps']['model'][0]\n",
    "feat_names_selected = results_individual['feat_names_selected']\n",
    "preds_test = m0.predict(X_test[feat_names_selected]) \n",
    "preds_new = m0.predict(X_new[feat_names_selected]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundd(x):\n",
    "    try:\n",
    "        return x.round(2)\n",
    "    except:\n",
    "        return [y.round(2) for y in x]\n",
    "r_long = {}\n",
    "for s in train.scorers:\n",
    "    r_long[s] = [roundd(train.scorers[s](y_full_cv, preds_cv)),\n",
    "                 roundd(train.scorers[s](y_test, preds_test)), \n",
    "                 roundd(train.scorers[s](y_new, preds_new))]\n",
    "\n",
    "def mean_diff(df, k, preds):\n",
    "    return np.mean(df[k][preds==1] - df[k][preds==0])\n",
    "    \n",
    "for k in ['X_max']:\n",
    "    r_long[k] = [mean_diff(df_cv, k, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_recall_curve</th>\n",
       "      <td>[[0.5, 0.75, 1.0], [1.0, 0.78, 0.0], [0.0, 1.0]]</td>\n",
       "      <td>[[0.22, 0.39, 1.0], [1.0, 0.93, 0.0], [0.0, 1.0]]</td>\n",
       "      <td>[[0.28, 0.59, 1.0], [1.0, 0.43, 0.0], [0.0, 1.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_curve</th>\n",
       "      <td>[[0.0, 0.26, 1.0], [0.0, 0.78, 1.0], [2.0, 1.0...</td>\n",
       "      <td>[[0.0, 0.41, 1.0], [0.0, 0.93, 1.0], [2.0, 1.0...</td>\n",
       "      <td>[[0.0, 0.12, 1.0], [0.0, 0.43, 1.0], [2.0, 1.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    train  \\\n",
       "balanced_accuracy                                                    0.76   \n",
       "accuracy                                                             0.76   \n",
       "precision                                                            0.75   \n",
       "recall                                                               0.78   \n",
       "f1                                                                   0.76   \n",
       "roc_auc                                                              0.76   \n",
       "precision_recall_curve   [[0.5, 0.75, 1.0], [1.0, 0.78, 0.0], [0.0, 1.0]]   \n",
       "roc_curve               [[0.0, 0.26, 1.0], [0.0, 0.78, 1.0], [2.0, 1.0...   \n",
       "\n",
       "                                                                     test  \\\n",
       "balanced_accuracy                                                    0.76   \n",
       "accuracy                                                             0.66   \n",
       "precision                                                            0.39   \n",
       "recall                                                               0.93   \n",
       "f1                                                                   0.55   \n",
       "roc_auc                                                              0.76   \n",
       "precision_recall_curve  [[0.22, 0.39, 1.0], [1.0, 0.93, 0.0], [0.0, 1.0]]   \n",
       "roc_curve               [[0.0, 0.41, 1.0], [0.0, 0.93, 1.0], [2.0, 1.0...   \n",
       "\n",
       "                                                                      new  \n",
       "balanced_accuracy                                                    0.66  \n",
       "accuracy                                                             0.76  \n",
       "precision                                                            0.59  \n",
       "recall                                                               0.43  \n",
       "f1                                                                    0.5  \n",
       "roc_auc                                                              0.66  \n",
       "precision_recall_curve  [[0.28, 0.59, 1.0], [1.0, 0.43, 0.0], [0.0, 1.0]]  \n",
       "roc_curve               [[0.0, 0.12, 1.0], [0.0, 0.43, 1.0], [2.0, 1.0...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.DataFrame.from_dict(r_long).transpose()\n",
    "r.columns = ['train', 'test', 'new']\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_confusion_matrix(y_test, preds, \n",
    "                          classes=np.array(['aux-', 'aux+']), normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in train.scorers:\n",
    "    print(s, f'train: {roundd(train.scorers[s](y_full_cv, preds_cv))}\\ttest: {roundd(train.scorers[s](y_new, preds_test))}')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
