{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "['total_displacement', 'mean_square_displacement', 'lifetime', 'center_max', 'left_max', 'right_max', 'up_max', 'down_max', 'X_max', 'X_min', 'X_mean', 'X_std', 'rise', 'fall', 'max_diff', 'min_diff', 'sc_0', 'sc_1', 'sc_2', 'sc_3', 'sc_4', 'sc_5', 'sc_6', 'sc_7', 'sc_8', 'sc_9', 'sc_10', 'sc_11', 'nmf_0', 'nmf_1', 'nmf_2', 'nmf_3', 'nmf_4', 'nmf_5', 'nmf_6', 'nmf_7', 'nmf_8', 'nmf_9', 'nmf_10', 'nmf_11', 'X_max_spl', 'dx_max_spl', 'd2x_max_spl', 'num_local_max_spl', 'num_local_min_spl']\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join as oj\n",
    "from sklearn import metrics\n",
    "#import eli5\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "plt.style.use('dark_background')\n",
    "import mat4py\n",
    "import pandas as pd\n",
    "import data_tracks\n",
    "import models\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from colorama import Fore\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "import train\n",
    "from style import *\n",
    "from sklearn import decomposition\n",
    "import viz\n",
    "\n",
    "df = data_tracks.get_data() #use_processed=False, use_processed_dicts=False)\n",
    "n = df.shape[0]\n",
    "feat_names = data_tracks.get_feature_names(df)\n",
    "print(feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop over classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:00<00:00, 29.39s/it]\n"
     ]
    }
   ],
   "source": [
    "outcome_def = 'y_consec_sig'\n",
    "out_dir = f'results/outcome={outcome_def}'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "for feature_selection in ['select_rf']: #, 'select_lasso']: # select_lasso\n",
    "    for balancing in ['ros']: # none\n",
    "        for model_type in tqdm(['irf', 'logistic', 'dt', 'rf', 'mlp2', 'dt', 'svm']): #,'gb', 'logistic', 'dt', 'svm', 'gb', rf', 'mlp2', 'irf']):\n",
    "            for num_feats in [15, 25, len(feat_names)]: # number of total features to consider\n",
    "                for feature_selection_num in [3, 5, 7, 11, 15]: # number of feature to select [4, 9, 11, 23, 35, 39]\n",
    "                    feats = feat_names[:num_feats]\n",
    "                    out_name = f'{model_type}_{num_feats}_{balancing}_{feature_selection}={feature_selection_num}'\n",
    "                    #print(out_name)\n",
    "                    train.train(df, feat_names=feats, model_type=model_type, \n",
    "                                balancing=balancing, outcome_def=outcome_def,\n",
    "                                feature_selection=feature_selection,\n",
    "                                feature_selection_num=feature_selection_num,\n",
    "                                out_name=f'{out_dir}/{out_name}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim reduction with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats_to_reduce = feat_names[:11] \n",
    "feats_to_reduce = feat_names\n",
    "X = df[feat_names]\n",
    "X = (X - X.mean()) / X.std()\n",
    "y = df['y_thresh'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**look at pcs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform pca\n",
    "pca = decomposition.PCA(whiten=True)\n",
    "# pca = decomposition.SparsePCA()\n",
    "# pca = decomposition.NMF()\n",
    "pca.fit(X)\n",
    "plt.figure(figsize=(6, 9), dpi=200)\n",
    "# plt.figure(figsize=(6, 5), dpi=200)\n",
    "viz.plot_pcs(pca, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "plt.figure(dpi=200)\n",
    "ys_neg = df['y_thresh'].values == 0\n",
    "plt.plot(X_reduced[:, 0][ys_neg], X_reduced[:, 1][ys_neg], 'o', \n",
    "         color=cr, alpha=0.3, markeredgewidth=0, ms=2) #, c=df['y_thresh'].values, alpha=0.1)\n",
    "plt.plot(X_reduced[:, 0][~ys_neg], X_reduced[:, 1][~ys_neg], 'o', \n",
    "         color=cb, alpha=0.3, markeredgewidth=0, ms=2)\n",
    "# plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=df['y_thresh'].values, alpha=0.1, cmap={0:'red', 1:'blue'})\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "#             cdf[np.arange(X.shape[0]), cmap='viridis', alpha=0.1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
