{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join as oj\n",
    "from sklearn import metrics\n",
    "#import eli5\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from sklearn import metrics\n",
    "plt.style.use('dark_background')\n",
    "import mat4py\n",
    "import pandas as pd\n",
    "import data_tracks\n",
    "import models\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from colorama import Fore\n",
    "import pickle as pkl\n",
    "from tqdm import tqdm\n",
    "import train\n",
    "from style import *\n",
    "from sklearn import decomposition\n",
    "import matplotlib.gridspec as grd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'X_pvals', 'Y_pvals', 'pixel', 'pixel_left', 'pixel_right',\n",
       "       'pixel_up', 'pixel_down', 'catIdx', 'total_displacement',\n",
       "       'mean_square_displacement', 'lifetime', 'x_pos', 'y_pos', 'center_max',\n",
       "       'left_max', 'right_max', 'up_max', 'down_max', 'cell_num', 'X_max',\n",
       "       'X_min', 'X_mean', 'X_std', 'Y_max', 'Y_mean', 'Y_std', 'rise', 'fall',\n",
       "       'max_diff', 'min_diff', 'y_score', 'y_thresh', 'y', 'y_single_sig',\n",
       "       'y_double_sig', 'y_consec_sig', 'sc_0', 'sc_1', 'sc_2', 'sc_3', 'sc_4',\n",
       "       'sc_5', 'sc_6', 'sc_7', 'sc_8', 'sc_9', 'sc_10', 'sc_11', 'nmf_0',\n",
       "       'nmf_1', 'nmf_2', 'nmf_3', 'nmf_4', 'nmf_5', 'nmf_6', 'nmf_7', 'nmf_8',\n",
       "       'nmf_9', 'nmf_10', 'nmf_11', 'X_smooth_spl', 'X_smooth_spl_dx',\n",
       "       'X_smooth_spl_d2x', 'X_max_spl', 'dx_max_spl', 'd2x_max_spl',\n",
       "       'num_local_max_spl', 'num_local_min_spl'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()\n",
    "# print(len(df.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 ['total_displacement', 'mean_square_displacement', 'lifetime', 'center_max', 'left_max', 'right_max', 'up_max', 'down_max', 'X_max', 'X_min', 'X_mean', 'X_std', 'rise', 'fall', 'max_diff', 'min_diff', 'sc_0', 'sc_1', 'sc_2', 'sc_3', 'sc_4', 'sc_5', 'sc_6', 'sc_7', 'sc_8', 'sc_9', 'sc_10', 'sc_11', 'nmf_0', 'nmf_1', 'nmf_2', 'nmf_3', 'nmf_4', 'nmf_5', 'nmf_6', 'nmf_7', 'nmf_8', 'nmf_9', 'nmf_10', 'nmf_11', 'X_max_spl', 'dx_max_spl', 'd2x_max_spl', 'num_local_max_spl', 'num_local_min_spl']\n"
     ]
    }
   ],
   "source": [
    "df = data_tracks.get_data() #use_processed=False, use_processed_dicts=False)\n",
    "n = df.shape[0]\n",
    "feat_names = data_tracks.get_feature_names(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop over classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:00<00:00, 29.39s/it]\n"
     ]
    }
   ],
   "source": [
    "outcome_def = 'y_consec_sig'\n",
    "out_dir = f'results/outcome={outcome_def}'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "for feature_selection in ['select_rf']: #, 'select_lasso']: # select_lasso\n",
    "    for balancing in ['ros']: # none\n",
    "        for model_type in tqdm(['irf', 'logistic', 'dt', 'rf', 'mlp2', 'dt', 'svm']): #,'gb', 'logistic', 'dt', 'svm', 'gb', rf', 'mlp2', 'irf']):\n",
    "            for num_feats in [15, 25, len(feat_names)]: # number of total features to consider\n",
    "                for feature_selection_num in [3, 5, 7, 11, 15]: # number of feature to select [4, 9, 11, 23, 35, 39]\n",
    "                    feats = feat_names[:num_feats]\n",
    "                    out_name = f'{model_type}_{num_feats}_{balancing}_{feature_selection}={feature_selection_num}'\n",
    "                    #print(out_name)\n",
    "                    train.train(df, feat_names=feats, model_type=model_type, \n",
    "                                balancing=balancing, outcome_def=outcome_def,\n",
    "                                feature_selection=feature_selection,\n",
    "                                feature_selection_num=feature_selection_num,\n",
    "                                out_name=f'{out_dir}/{out_name}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dim reduction with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats_to_reduce = feat_names[:11] \n",
    "feats_to_reduce = feat_names\n",
    "X = df[feat_names]\n",
    "X = (X - X.mean()) / X.std()\n",
    "y = df['y_thresh'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**look at pcs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pcs(pca):\n",
    "    '''Pretty plot of pcs with explained var bars\n",
    "    Params\n",
    "    ------\n",
    "    pca: sklearn PCA class after being fitted\n",
    "    '''\n",
    "    # extract out relevant pars\n",
    "    comps = pca.components_.transpose()\n",
    "    var_norm = pca.explained_variance_ / np.sum(pca.explained_variance_) * 100\n",
    "    \n",
    "    \n",
    "    # create a 2 X 2 grid \n",
    "    gs = grd.GridSpec(2, 2, height_ratios=[2,10], \n",
    "                      width_ratios=[12, 1], wspace=0.1, hspace=0)\n",
    "\n",
    "    \n",
    "    # plot explained variance\n",
    "    ax2 = plt.subplot(gs[0])\n",
    "    ax2.bar(np.arange(0, comps.shape[1]), var_norm, \n",
    "            color='gray', width=0.8)\n",
    "    plt.title('Explained variance (%)')\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.yaxis.set_ticks_position('left')\n",
    "    ax2.set_yticks([0, max(var_norm)])\n",
    "    plt.xlim((-0.5, comps.shape[1]-0.5))\n",
    "    \n",
    "    # plot pcs\n",
    "    ax = plt.subplot(gs[2])\n",
    "    vmaxabs = np.max(np.abs(comps))\n",
    "    p = ax.imshow(comps, interpolation='None', aspect='auto',\n",
    "                  cmap=sns.diverging_palette(10, 240, as_cmap=True, center='light'),\n",
    "                  vmin=-vmaxabs, vmax=vmaxabs) # center at 0\n",
    "    plt.xlabel('PCA component number')\n",
    "    ax.set_yticklabels(list(X))\n",
    "    ax.set_yticks(range(len(list(X))))\n",
    "    \n",
    "\n",
    "    # make colorbar\n",
    "    colorAx = plt.subplot(gs[3])\n",
    "    cb = plt.colorbar(p, cax=colorAx)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# perform pca\n",
    "pca = decomposition.PCA(whiten=True)\n",
    "# pca = decomposition.SparsePCA()\n",
    "# pca = decomposition.NMF()\n",
    "pca.fit(X)\n",
    "\n",
    "plt.figure(figsize=(6, 9), dpi=200)\n",
    "# plt.figure(figsize=(6, 5), dpi=200)\n",
    "plot_pcs(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "plt.figure(dpi=200)\n",
    "ys_neg = df['y_thresh'].values == 0\n",
    "plt.plot(X_reduced[:, 0][ys_neg], X_reduced[:, 1][ys_neg], 'o', \n",
    "         color=cr, alpha=0.3, markeredgewidth=0, ms=2) #, c=df['y_thresh'].values, alpha=0.1)\n",
    "plt.plot(X_reduced[:, 0][~ys_neg], X_reduced[:, 1][~ys_neg], 'o', \n",
    "         color=cb, alpha=0.3, markeredgewidth=0, ms=2)\n",
    "# plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=df['y_thresh'].values, alpha=0.1, cmap={0:'red', 1:'blue'})\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "#             cdf[np.arange(X.shape[0]), cmap='viridis', alpha=0.1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
