<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>src.data API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.data</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import sys
from copy import deepcopy
from os.path import join as oj

sys.path.append(&#39;..&#39;)
import mat4py
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt
from skimage.external.tifffile import imread

pd.options.mode.chained_assignment = None  # default=&#39;warn&#39; - caution: this turns off setting with copy warning
import pickle as pkl
from viz import *
import math
import config
import features
import outcomes


def get_data(dset=&#39;clath_aux+gak_a7d2&#39;, use_processed=True, save_processed=True, processed_file=&#39;processed/df.pkl&#39;,
             metadata_file=&#39;processed/metadata.pkl&#39;, use_processed_dicts=True,
             outcome_def=&#39;y_consec_thresh&#39;, all_data=False, acc_thresh=0.95,
             previous_meta_file=None):
    &#39;&#39;&#39;
    Params
    ------
    use_processed: bool, optional
        determines whether to load df from cached pkl
    save_processed: bool, optional
        if not using processed, determines whether to save the df
    use_processed_dicts: bool, optional
        if False, recalculate the dictionary features
    previous_meta_file: str, optional
        filename for metadata.pkl file saved by previous preprocessing
        the thresholds for lifetime are taken from this file
    &#39;&#39;&#39;
    # get things based onn dset
    DSET = config.DSETS[dset]
    LABELS = config.LABELS[dset]

    processed_file = processed_file[:-4] + &#39;_&#39; + dset + &#39;.pkl&#39;
    metadata_file = metadata_file[:-4] + &#39;_&#39; + dset + &#39;.pkl&#39;

    if use_processed and os.path.exists(processed_file):
        return pd.read_pickle(processed_file)
    else:
        print(&#39;loading + preprocessing data...&#39;)
        metadata = {}
        print(&#39;\tloading tracks...&#39;)
        df = get_tracks(data_dir=DSET[&#39;data_dir&#39;], split=DSET, all_data=all_data,
                        dset=dset)  # note: different Xs can be different shapes
        df[&#39;pid&#39;] = np.arange(df.shape[0])  # assign each track a unique id
        df[&#39;valid&#39;] = True  # all tracks start as valid
        df[&#39;valid&#39;][df.cell_num.isin(DSET[&#39;test&#39;])] = False
        metadata[&#39;num_tracks&#39;] = df.valid.sum()

        print(&#39;\tpreprocessing data...&#39;)
        df = remove_invalid_tracks(df)  # use catIdx
        df = features.add_basic_features(df)
        df = outcomes.add_outcomes(df, LABELS=LABELS)

        metadata[&#39;num_tracks_valid&#39;] = df.valid.sum()
        metadata[&#39;num_aux_pos_valid&#39;] = df[df.valid][outcome_def].sum()
        metadata[&#39;num_hotspots_valid&#39;] = df[df.valid][&#39;hotspots&#39;].sum()
        df[&#39;valid&#39;][df.hotspots] = False
        df, meta_lifetime = process_tracks_by_lifetime(df, outcome_def=outcome_def,
                                                       plot=False, acc_thresh=acc_thresh,
                                                       previous_meta_file=previous_meta_file)
        df[&#39;valid&#39;][df.short] = False
        df[&#39;valid&#39;][df.long] = False
        metadata.update(meta_lifetime)
        metadata[&#39;num_tracks_hard&#39;] = df[&#39;valid&#39;].sum()
        metadata[&#39;num_aux_pos_hard&#39;] = int(df[df.valid == 1][outcome_def].sum())

        print(&#39;\tadding features...&#39;)
        # df = features.add_dict_features(df, use_processed=use_processed_dicts)
        # df = features.add_smoothed_tracks(df)
        df = features.add_pcs(df)
        # df = features.add_trend_filtering(df) 
        df = features.add_binary_features(df, outcome_def=outcome_def)
        if save_processed:
            pkl.dump(metadata, open(metadata_file, &#39;wb&#39;))
            df.to_pickle(processed_file)
    return df


def get_images(cell_dir: str):
    &#39;&#39;&#39;Loads in X and Y for one cell
    
    Params
    ------
    cell_dir
        Path to directory for one cell
    
    Returns
    -------
    X : np.ndarray
        has shape (W, H, num_images)
    Y : np.ndarray
        has shape (W, H, num_images)
    &#39;&#39;&#39;
    for name in os.listdir(oj(cell_dir, &#39;TagRFP&#39;)):
        if &#39;tif&#39; in name:
            fname1 = name
    for name in os.listdir(oj(cell_dir, &#39;EGFP&#39;)):
        if &#39;tif&#39; in name:
            fname2 = name
    X = imread(oj(cell_dir, &#39;TagRFP&#39;, fname1))  # .astype(np.float32) # X = RFP(clathrin) (num_images x H x W)
    Y = imread(oj(cell_dir, &#39;EGFP&#39;, fname2))  # .astype(np.float32) # Y = EGFP (auxilin) (num_image x H x W)
    return X, Y


def get_tracks(data_dir, split=None, all_data=False, processed_tracks_file=&#39;processed/tracks.pkl&#39;, dset=&#39;orig&#39;):
    &#39;&#39;&#39;Read out tracks from folders within data_dir, assuming tracking has been done
    &#39;&#39;&#39;
    processed_tracks_file = processed_tracks_file[:-4] + &#39;_&#39; + dset + &#39;.pkl&#39;
    print(&#39;\t&#39;, processed_tracks_file, data_dir)

    if os.path.exists(processed_tracks_file):
        return pd.read_pickle(processed_tracks_file)
    dfs = []

    if split is not None:
        flatten = lambda l: [item for sublist in l for item in sublist]
        split = flatten(split.values())

    # 2 directories of naming
    for upper_dir in sorted(os.listdir(data_dir)):
        if &#39;.&#39; in upper_dir or &#39;Icon&#39; in upper_dir:
            continue
        for cell_dir in sorted(os.listdir(oj(data_dir, upper_dir))):
            if not &#39;Cell&#39; in cell_dir:
                continue
            cell_num = oj(upper_dir, cell_dir.replace(&#39;Cell&#39;, &#39;&#39;).replace(&#39;_1s&#39;, &#39;&#39;))
            if split is not None:
                if not cell_num in split:
                    continue
            full_dir = f&#39;{data_dir}/{upper_dir}/{cell_dir}&#39;
            fname = full_dir + &#39;/TagRFP/Tracking/ProcessedTracks.mat&#39;
            print(cell_num)
            cla, aux = get_images(full_dir)
            # fname_image = oj(data_dir, upper_dir, cell_dir)
            mat = mat4py.loadmat(fname)
            tracks = mat[&#39;tracks&#39;]
            n = len(tracks[&#39;t&#39;])
            totalDisplacement = []
            msd = []  # mean squared displacement
            for i in range(n):
                try:
                    totalDisplacement.append(tracks[&#39;MotionAnalysis&#39;][i][&#39;totalDisplacement&#39;])
                except:
                    totalDisplacement.append(0)
                try:
                    msd.append(np.nanmax(tracks[&#39;MotionAnalysis&#39;][i][&#39;MSD&#39;]))
                except:
                    msd.append(0)

            CLATH = 0
            AUX = 1

            X = np.array([tracks[&#39;A&#39;][i][CLATH] for i in range(n)])
            Y = np.array([tracks[&#39;A&#39;][i][AUX] for i in range(n)])
            t = np.array([tracks[&#39;t&#39;][i] for i in range(n)])
            x_pos_seq = np.array(
                [tracks[&#39;x&#39;][i][CLATH] for i in range(n)])  # x-position for clathrin (auxilin is very similar)
            y_pos_seq = np.array(
                [tracks[&#39;y&#39;][i][CLATH] for i in range(n)])  # y-position for clathrin (auxilin is very similar)
            X_pvals = np.array([tracks[&#39;pval_Ar&#39;][i][CLATH] for i in range(n)])
            Y_pvals = np.array([tracks[&#39;pval_Ar&#39;][i][AUX] for i in range(n)])

            # buffers
            X_starts = []
            Y_starts = []
            for d in tracks[&#39;startBuffer&#39;]:
                if len(d) == 0:
                    X_starts.append([])
                    Y_starts.append([])
                else:
                    X_starts.append(d[&#39;A&#39;][CLATH])
                    Y_starts.append(d[&#39;A&#39;][AUX])
            X_ends = []
            Y_ends = []
            for d in tracks[&#39;endBuffer&#39;]:
                if len(d) == 0:
                    X_ends.append([])
                    Y_ends.append([])
                else:
                    X_ends.append(d[&#39;A&#39;][CLATH])
                    Y_ends.append(d[&#39;A&#39;][AUX])
            X_extended = [X_starts[i] + X[i] + X_ends[i] for i in range(n)]

            # image feats
            pixel = np.array([[cla[int(t[i][j]), int(y_pos_seq[i][j]), int(x_pos_seq[i][j])]
                               if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                              for i in range(n)])
            pixel_up = np.array(
                [[cla[int(t[i][j]), min(int(y_pos_seq[i][j] + 1), cla.shape[1] - 1), int(x_pos_seq[i][j])]
                  if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                 for i in range(n)])
            pixel_down = np.array([[cla[int(t[i][j]), max(int(y_pos_seq[i][j] - 1), 0), int(x_pos_seq[i][j])]
                                    if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                                   for i in range(n)])
            pixel_left = np.array([[cla[int(t[i][j]), int(y_pos_seq[i][j]), max(int(x_pos_seq[i][j] - 1), 0)]
                                    if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                                   for i in range(n)])
            pixel_right = np.array(
                [[cla[int(t[i][j]), int(y_pos_seq[i][j]), min(int(x_pos_seq[i][j] + 1), cla.shape[2] - 1)]
                  if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                 for i in range(n)])

            data = {
                &#39;X&#39;: X,
                &#39;X_extended&#39;: X_extended,
                &#39;Y&#39;: Y,
                &#39;X_starts&#39;: X_starts,
                &#39;Y_starts&#39;: Y_starts,
                &#39;X_ends&#39;: X_ends,
                &#39;Y_ends&#39;: Y_ends,
                &#39;X_pvals&#39;: X_pvals,
                &#39;Y_pvals&#39;: Y_pvals,
                &#39;catIdx&#39;: tracks[&#39;catIdx&#39;],
                &#39;mean_total_displacement&#39;: [totalDisplacement[i] / tracks[&#39;lifetime_s&#39;][i] for i in range(n)],
                &#39;mean_square_displacement&#39;: msd,
                &#39;lifetime&#39;: tracks[&#39;lifetime_s&#39;],
                &#39;lifetime_extended&#39;: [len(x) for x in X_extended],
                &#39;x_pos&#39;: [sum(x) / len(x) for x in x_pos_seq],  # mean position in the image
                &#39;y_pos&#39;: [sum(y) / len(y) for y in y_pos_seq],
                &#39;cell_num&#39;: [cell_num] * n,
                &#39;t&#39;: [t[i][0] for i in range(n)],
                &#39;x_pos_seq&#39;: x_pos_seq,
                &#39;y_pos_seq&#39;: y_pos_seq,
            }
            if all_data:
                data[&#39;t&#39;] = [t[i][0] for i in range(n)]
                data[&#39;pixel&#39;] = pixel
                data[&#39;pixel_left&#39;] = pixel_left
                data[&#39;pixel_right&#39;] = pixel_right
                data[&#39;pixel_up&#39;] = pixel_up
                data[&#39;pixel_down&#39;] = pixel_down
                data[&#39;center_max&#39;] = [max(pixel[i]) for i in range(n)],
                data[&#39;left_max&#39;] = [max(pixel_left[i]) for i in range(n)],
                data[&#39;right_max&#39;] = [max(pixel_right[i]) for i in range(n)],
                data[&#39;up_max&#39;] = [max(pixel_up[i]) for i in range(n)],
                data[&#39;down_max&#39;] = [max(pixel_down[i]) for i in range(n)],
            df = pd.DataFrame.from_dict(data)
            dfs.append(deepcopy(df))
    df = pd.concat(dfs)
    os.makedirs(os.path.dirname(processed_tracks_file), exist_ok=True)
    df.to_pickle(processed_tracks_file)
    return df


def remove_invalid_tracks(df, keep=[1, 2]):
    &#39;&#39;&#39;Remove certain types of tracks based on cat_idx
    cat_idx (idx 1 and 2)
        1-4 (non-complex trajectory - no merges and splits)
            1 - valid
            2 - signal occasionally drops out
            3 - cut  - starts / ends
            4 - multiple - at the same place (continues throughout)
        5-8 (there is merging or splitting)
    &#39;&#39;&#39;
    df[&#39;lifetime_ref&#39;] = [len(x) for x in df[&#39;X&#39;]]
    no_nan = df[&#39;lifetime&#39;] == df[&#39;lifetime_ref&#39;]
    df = df[no_nan]
    return df[df.catIdx.isin(keep)]


def extract_X_mat(df):
    &#39;&#39;&#39;Extract matrix for X filled with zeros after sequences
    Width of matrix is length of longest lifetime
    &#39;&#39;&#39;
    p = df.lifetime.max()
    n = df.shape[0]
    X_mat = np.zeros((n, p)).astype(np.float32)
    X = df[&#39;X&#39;].values
    for i in range(n):
        x = X[i]
        num_timepoints = min(p, len(x))
        X_mat[i, :num_timepoints] = x[:num_timepoints]
    X_mat = np.nan_to_num(X_mat)
    X_mat -= np.min(X_mat)
    X_mat /= np.std(X_mat)
    return X_mat


def process_tracks_by_lifetime(df: pd.DataFrame, outcome_def: str,
                               plot=False, acc_thresh=0.95, previous_meta_file=None):
    &#39;&#39;&#39;Calculate accuracy you can get by just predicting max class 
    as a func of lifetime and return points within proper lifetime (only looks at training cells)
    &#39;&#39;&#39;
    vals = df[df.valid == 1][[&#39;lifetime&#39;, outcome_def]]

    R, C = 1, 3
    lifetimes = np.unique(vals[&#39;lifetime&#39;])

    # cumulative accuracy for different thresholds
    accs_cum_lower = np.array([1 - np.mean(vals[outcome_def][vals[&#39;lifetime&#39;] &lt;= l]) for l in lifetimes])
    accs_cum_higher = np.array([np.mean(vals[outcome_def][vals[&#39;lifetime&#39;] &gt;= l]) for l in lifetimes]).flatten()

    if previous_meta_file is None:
        try:
            idx_thresh = np.nonzero(accs_cum_lower &gt;= acc_thresh)[0][-1]  # last nonzero index
            thresh_lower = lifetimes[idx_thresh]
        except:
            idx_thresh = 0
            thresh_lower = lifetimes[idx_thresh] - 1
        try:
            idx_thresh_2 = np.nonzero(accs_cum_higher &gt;= acc_thresh)[0][0]
            thresh_higher = lifetimes[idx_thresh_2]
        except:
            idx_thresh_2 = lifetimes.size - 1
            thresh_higher = lifetimes[idx_thresh_2] + 1
    else:
        previous_meta = pkl.load(open(previous_meta_file, &#39;rb&#39;))
        thresh_lower = previous_meta[&#39;thresh_short&#39;]
        thresh_higher = previous_meta[&#39;thresh_long&#39;]

    # only df with lifetimes in proper range
    df[&#39;short&#39;] = df[&#39;lifetime&#39;] &lt;= thresh_lower
    df[&#39;long&#39;] = df[&#39;lifetime&#39;] &gt;= thresh_higher
    n = vals.shape[0]
    n_short = np.sum(df[&#39;short&#39;])
    n_long = np.sum(df[&#39;long&#39;])
    acc_short = 1 - np.mean(vals[outcome_def][vals[&#39;lifetime&#39;] &lt;= thresh_lower])
    acc_long = np.mean(vals[outcome_def][vals[&#39;lifetime&#39;] &gt;= thresh_higher])

    metadata = {&#39;num_short&#39;: n_short, &#39;num_long&#39;: n_long, &#39;acc_short&#39;: acc_short,
                &#39;acc_long&#39;: acc_long, &#39;thresh_short&#39;: thresh_lower, &#39;thresh_long&#39;: thresh_higher}

    if plot:
        plt.figure(figsize=(12, 4), dpi=200)
        plt.subplot(R, C, 1)
        outcome = df[outcome_def]
        plt.hist(df[&#39;lifetime&#39;][outcome == 1], label=&#39;aux+&#39;, alpha=1, color=cb, bins=25)
        plt.hist(df[&#39;lifetime&#39;][outcome == 0], label=&#39;aux-&#39;, alpha=0.7, color=cr, bins=25)
        plt.xlabel(&#39;lifetime&#39;)
        plt.ylabel(&#39;count&#39;)
        plt.legend()

        plt.subplot(R, C, 2)
        plt.plot(lifetimes, accs_cum_lower, color=cr)
        #     plt.axvline(thresh_lower)
        plt.axvspan(0, thresh_lower, alpha=0.2, color=cr)
        plt.ylabel(&#39;fraction of negative events&#39;)
        plt.xlabel(f&#39;lifetime &lt;= value\nshaded includes {n_short / n * 100:0.0f}% of pts&#39;)

        plt.subplot(R, C, 3)
        plt.plot(lifetimes, accs_cum_higher, cb)
        plt.axvspan(thresh_higher, max(lifetimes), alpha=0.2, color=cb)
        plt.ylabel(&#39;fraction of positive events&#39;)
        plt.xlabel(f&#39;lifetime &gt;= value\nshaded includes {n_long / n * 100:0.0f}% of pts&#39;)
        plt.tight_layout()

    return df, metadata


def get_feature_names(df):
    &#39;&#39;&#39;Returns features (all of which are scalar)
    Removes metadata + time-series columns + outcomes
    &#39;&#39;&#39;
    ks = list(df.keys())
    feat_names = [
        k for k in ks
        if not k.startswith(&#39;y&#39;)
           and not k.startswith(&#39;Y&#39;)
           and not k.startswith(&#39;pixel&#39;)
           #         and not k.startswith(&#39;pc_&#39;)
           and not k in [&#39;catIdx&#39;, &#39;cell_num&#39;, &#39;pid&#39;, &#39;valid&#39;,  # metadata
                         &#39;X&#39;, &#39;X_pvals&#39;, &#39;x_pos&#39;, &#39;X_starts&#39;, &#39;X_ends&#39;, &#39;X_extended&#39;,  # curves
                         &#39;short&#39;, &#39;long&#39;, &#39;hotspots&#39;, &#39;sig_idxs&#39;,  # should be weeded out
                         &#39;X_max_around_Y_peak&#39;, &#39;X_max_after_Y_peak&#39;,  # redudant with X_max / fall
                         &#39;X_max_diff&#39;, &#39;X_peak_idx&#39;,  # unlikely to be useful
                         &#39;t&#39;, &#39;x_pos_seq&#39;, &#39;y_pos_seq&#39;,  # curves
                         &#39;X_smooth_spl&#39;, &#39;X_smooth_spl_dx&#39;, &#39;X_smooth_spl_d2x&#39;  # curves
                         ]
    ]
    return feat_names


def select_final_feats(feat_names, binarize=False):
    feat_names = [x for x in feat_names
                  if not x.startswith(&#39;sc_&#39;)
                  and not x.startswith(&#39;nmf_&#39;)
                  and not x in [&#39;center_max&#39;, &#39;left_max&#39;, &#39;right_max&#39;, &#39;up_max&#39;, &#39;down_max&#39;,
                                &#39;X_max_around_Y_peak&#39;, &#39;X_max_after_Y_peak&#39;, &#39;X_max_diff_after_Y_peak&#39;]
                  and not x.startswith(&#39;pc_&#39;)
                  and not &#39;extended&#39; in x
                  #               and not &#39;X_peak&#39; in x
                  #               and not &#39;slope&#39; in x
                  #               and not x in [&#39;fall_final&#39;, &#39;fall_slope&#39;, &#39;fall_imp&#39;, &#39;fall&#39;]
                  ]
    feat_names = [x for x in feat_names if not &#39;_tf_smooth&#39; in x]
    feat_names = [x for x in feat_names if not &#39;local&#39; in x]
    feat_names = [x for x in feat_names if not &#39;last&#39; in x]
    # feat_names = [x for x in feat_names if &#39;_tf_smooth&#39; in x]

    if binarize:
        feat_names = [x for x in feat_names if &#39;binary&#39; in x]
    else:
        feat_names = [x for x in feat_names if not &#39;binary&#39; in x]
    return feat_names


if __name__ == &#39;__main__&#39;:
    # process original data (and save out lifetime thresholds)
    dset_orig = &#39;clath_aux+gak_a7d2&#39;
    df = get_data(dset=dset_orig)  # save out orig
    outcome_def = &#39;y_consec_sig&#39;
    for dset in config.DSETS.keys():
        # process new data (using lifetime thresholds from original data)
        df = get_data(dset=dset,
                      previous_meta_file=f&#39;processed/metadata_{dset_orig}.pkl&#39;)
        print(dset, &#39;num cells&#39;, len(df[&#39;cell_num&#39;].unique()), &#39;num tracks&#39;, df.shape[0], &#39;num aux+&#39;,
              df[outcome_def].sum(), &#39;ratio&#39;, (df[outcome_def].sum() / df.shape[0]).round(3),
              &#39;valid&#39;, df.valid.sum(), &#39;valid aux+&#39;, df[df.valid][outcome_def].sum(), &#39;ratio&#39;,
              (df[df.valid][outcome_def].sum() / df.valid.sum()).round(3))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.data.extract_X_mat"><code class="name flex">
<span>def <span class="ident">extract_X_mat</span></span>(<span>df)</span>
</code></dt>
<dd>
<section class="desc"><p>Extract matrix for X filled with zeros after sequences
Width of matrix is length of longest lifetime</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def extract_X_mat(df):
    &#39;&#39;&#39;Extract matrix for X filled with zeros after sequences
    Width of matrix is length of longest lifetime
    &#39;&#39;&#39;
    p = df.lifetime.max()
    n = df.shape[0]
    X_mat = np.zeros((n, p)).astype(np.float32)
    X = df[&#39;X&#39;].values
    for i in range(n):
        x = X[i]
        num_timepoints = min(p, len(x))
        X_mat[i, :num_timepoints] = x[:num_timepoints]
    X_mat = np.nan_to_num(X_mat)
    X_mat -= np.min(X_mat)
    X_mat /= np.std(X_mat)
    return X_mat</code></pre>
</details>
</dd>
<dt id="src.data.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>dset='clath_aux+gak_a7d2', use_processed=True, save_processed=True, processed_file='processed/df.pkl', metadata_file='processed/metadata.pkl', use_processed_dicts=True, outcome_def='y_consec_thresh', all_data=False, acc_thresh=0.95, previous_meta_file=None)</span>
</code></dt>
<dd>
<section class="desc"><h2 id="params">Params</h2>
<dl>
<dt><strong><code>use_processed</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>determines whether to load df from cached pkl</dd>
<dt><strong><code>save_processed</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>if not using processed, determines whether to save the df</dd>
<dt><strong><code>use_processed_dicts</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>if False, recalculate the dictionary features</dd>
<dt><strong><code>previous_meta_file</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>filename for metadata.pkl file saved by previous preprocessing
the thresholds for lifetime are taken from this file</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data(dset=&#39;clath_aux+gak_a7d2&#39;, use_processed=True, save_processed=True, processed_file=&#39;processed/df.pkl&#39;,
             metadata_file=&#39;processed/metadata.pkl&#39;, use_processed_dicts=True,
             outcome_def=&#39;y_consec_thresh&#39;, all_data=False, acc_thresh=0.95,
             previous_meta_file=None):
    &#39;&#39;&#39;
    Params
    ------
    use_processed: bool, optional
        determines whether to load df from cached pkl
    save_processed: bool, optional
        if not using processed, determines whether to save the df
    use_processed_dicts: bool, optional
        if False, recalculate the dictionary features
    previous_meta_file: str, optional
        filename for metadata.pkl file saved by previous preprocessing
        the thresholds for lifetime are taken from this file
    &#39;&#39;&#39;
    # get things based onn dset
    DSET = config.DSETS[dset]
    LABELS = config.LABELS[dset]

    processed_file = processed_file[:-4] + &#39;_&#39; + dset + &#39;.pkl&#39;
    metadata_file = metadata_file[:-4] + &#39;_&#39; + dset + &#39;.pkl&#39;

    if use_processed and os.path.exists(processed_file):
        return pd.read_pickle(processed_file)
    else:
        print(&#39;loading + preprocessing data...&#39;)
        metadata = {}
        print(&#39;\tloading tracks...&#39;)
        df = get_tracks(data_dir=DSET[&#39;data_dir&#39;], split=DSET, all_data=all_data,
                        dset=dset)  # note: different Xs can be different shapes
        df[&#39;pid&#39;] = np.arange(df.shape[0])  # assign each track a unique id
        df[&#39;valid&#39;] = True  # all tracks start as valid
        df[&#39;valid&#39;][df.cell_num.isin(DSET[&#39;test&#39;])] = False
        metadata[&#39;num_tracks&#39;] = df.valid.sum()

        print(&#39;\tpreprocessing data...&#39;)
        df = remove_invalid_tracks(df)  # use catIdx
        df = features.add_basic_features(df)
        df = outcomes.add_outcomes(df, LABELS=LABELS)

        metadata[&#39;num_tracks_valid&#39;] = df.valid.sum()
        metadata[&#39;num_aux_pos_valid&#39;] = df[df.valid][outcome_def].sum()
        metadata[&#39;num_hotspots_valid&#39;] = df[df.valid][&#39;hotspots&#39;].sum()
        df[&#39;valid&#39;][df.hotspots] = False
        df, meta_lifetime = process_tracks_by_lifetime(df, outcome_def=outcome_def,
                                                       plot=False, acc_thresh=acc_thresh,
                                                       previous_meta_file=previous_meta_file)
        df[&#39;valid&#39;][df.short] = False
        df[&#39;valid&#39;][df.long] = False
        metadata.update(meta_lifetime)
        metadata[&#39;num_tracks_hard&#39;] = df[&#39;valid&#39;].sum()
        metadata[&#39;num_aux_pos_hard&#39;] = int(df[df.valid == 1][outcome_def].sum())

        print(&#39;\tadding features...&#39;)
        # df = features.add_dict_features(df, use_processed=use_processed_dicts)
        # df = features.add_smoothed_tracks(df)
        df = features.add_pcs(df)
        # df = features.add_trend_filtering(df) 
        df = features.add_binary_features(df, outcome_def=outcome_def)
        if save_processed:
            pkl.dump(metadata, open(metadata_file, &#39;wb&#39;))
            df.to_pickle(processed_file)
    return df</code></pre>
</details>
</dd>
<dt id="src.data.get_feature_names"><code class="name flex">
<span>def <span class="ident">get_feature_names</span></span>(<span>df)</span>
</code></dt>
<dd>
<section class="desc"><p>Returns features (all of which are scalar)
Removes metadata + time-series columns + outcomes</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_feature_names(df):
    &#39;&#39;&#39;Returns features (all of which are scalar)
    Removes metadata + time-series columns + outcomes
    &#39;&#39;&#39;
    ks = list(df.keys())
    feat_names = [
        k for k in ks
        if not k.startswith(&#39;y&#39;)
           and not k.startswith(&#39;Y&#39;)
           and not k.startswith(&#39;pixel&#39;)
           #         and not k.startswith(&#39;pc_&#39;)
           and not k in [&#39;catIdx&#39;, &#39;cell_num&#39;, &#39;pid&#39;, &#39;valid&#39;,  # metadata
                         &#39;X&#39;, &#39;X_pvals&#39;, &#39;x_pos&#39;, &#39;X_starts&#39;, &#39;X_ends&#39;, &#39;X_extended&#39;,  # curves
                         &#39;short&#39;, &#39;long&#39;, &#39;hotspots&#39;, &#39;sig_idxs&#39;,  # should be weeded out
                         &#39;X_max_around_Y_peak&#39;, &#39;X_max_after_Y_peak&#39;,  # redudant with X_max / fall
                         &#39;X_max_diff&#39;, &#39;X_peak_idx&#39;,  # unlikely to be useful
                         &#39;t&#39;, &#39;x_pos_seq&#39;, &#39;y_pos_seq&#39;,  # curves
                         &#39;X_smooth_spl&#39;, &#39;X_smooth_spl_dx&#39;, &#39;X_smooth_spl_d2x&#39;  # curves
                         ]
    ]
    return feat_names</code></pre>
</details>
</dd>
<dt id="src.data.get_images"><code class="name flex">
<span>def <span class="ident">get_images</span></span>(<span>cell_dir)</span>
</code></dt>
<dd>
<section class="desc"><p>Loads in X and Y for one cell</p>
<h2 id="params">Params</h2>
<dl>
<dt><strong><code>cell_dir</code></strong></dt>
<dd>Path to directory for one cell</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>X</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>has shape (W, H, num_images)</dd>
<dt><strong><code>Y</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>has shape (W, H, num_images)</dd>
</dl></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_images(cell_dir: str):
    &#39;&#39;&#39;Loads in X and Y for one cell
    
    Params
    ------
    cell_dir
        Path to directory for one cell
    
    Returns
    -------
    X : np.ndarray
        has shape (W, H, num_images)
    Y : np.ndarray
        has shape (W, H, num_images)
    &#39;&#39;&#39;
    for name in os.listdir(oj(cell_dir, &#39;TagRFP&#39;)):
        if &#39;tif&#39; in name:
            fname1 = name
    for name in os.listdir(oj(cell_dir, &#39;EGFP&#39;)):
        if &#39;tif&#39; in name:
            fname2 = name
    X = imread(oj(cell_dir, &#39;TagRFP&#39;, fname1))  # .astype(np.float32) # X = RFP(clathrin) (num_images x H x W)
    Y = imread(oj(cell_dir, &#39;EGFP&#39;, fname2))  # .astype(np.float32) # Y = EGFP (auxilin) (num_image x H x W)
    return X, Y</code></pre>
</details>
</dd>
<dt id="src.data.get_tracks"><code class="name flex">
<span>def <span class="ident">get_tracks</span></span>(<span>data_dir, split=None, all_data=False, processed_tracks_file='processed/tracks.pkl', dset='orig')</span>
</code></dt>
<dd>
<section class="desc"><p>Read out tracks from folders within data_dir, assuming tracking has been done</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_tracks(data_dir, split=None, all_data=False, processed_tracks_file=&#39;processed/tracks.pkl&#39;, dset=&#39;orig&#39;):
    &#39;&#39;&#39;Read out tracks from folders within data_dir, assuming tracking has been done
    &#39;&#39;&#39;
    processed_tracks_file = processed_tracks_file[:-4] + &#39;_&#39; + dset + &#39;.pkl&#39;
    print(&#39;\t&#39;, processed_tracks_file, data_dir)

    if os.path.exists(processed_tracks_file):
        return pd.read_pickle(processed_tracks_file)
    dfs = []

    if split is not None:
        flatten = lambda l: [item for sublist in l for item in sublist]
        split = flatten(split.values())

    # 2 directories of naming
    for upper_dir in sorted(os.listdir(data_dir)):
        if &#39;.&#39; in upper_dir or &#39;Icon&#39; in upper_dir:
            continue
        for cell_dir in sorted(os.listdir(oj(data_dir, upper_dir))):
            if not &#39;Cell&#39; in cell_dir:
                continue
            cell_num = oj(upper_dir, cell_dir.replace(&#39;Cell&#39;, &#39;&#39;).replace(&#39;_1s&#39;, &#39;&#39;))
            if split is not None:
                if not cell_num in split:
                    continue
            full_dir = f&#39;{data_dir}/{upper_dir}/{cell_dir}&#39;
            fname = full_dir + &#39;/TagRFP/Tracking/ProcessedTracks.mat&#39;
            print(cell_num)
            cla, aux = get_images(full_dir)
            # fname_image = oj(data_dir, upper_dir, cell_dir)
            mat = mat4py.loadmat(fname)
            tracks = mat[&#39;tracks&#39;]
            n = len(tracks[&#39;t&#39;])
            totalDisplacement = []
            msd = []  # mean squared displacement
            for i in range(n):
                try:
                    totalDisplacement.append(tracks[&#39;MotionAnalysis&#39;][i][&#39;totalDisplacement&#39;])
                except:
                    totalDisplacement.append(0)
                try:
                    msd.append(np.nanmax(tracks[&#39;MotionAnalysis&#39;][i][&#39;MSD&#39;]))
                except:
                    msd.append(0)

            CLATH = 0
            AUX = 1

            X = np.array([tracks[&#39;A&#39;][i][CLATH] for i in range(n)])
            Y = np.array([tracks[&#39;A&#39;][i][AUX] for i in range(n)])
            t = np.array([tracks[&#39;t&#39;][i] for i in range(n)])
            x_pos_seq = np.array(
                [tracks[&#39;x&#39;][i][CLATH] for i in range(n)])  # x-position for clathrin (auxilin is very similar)
            y_pos_seq = np.array(
                [tracks[&#39;y&#39;][i][CLATH] for i in range(n)])  # y-position for clathrin (auxilin is very similar)
            X_pvals = np.array([tracks[&#39;pval_Ar&#39;][i][CLATH] for i in range(n)])
            Y_pvals = np.array([tracks[&#39;pval_Ar&#39;][i][AUX] for i in range(n)])

            # buffers
            X_starts = []
            Y_starts = []
            for d in tracks[&#39;startBuffer&#39;]:
                if len(d) == 0:
                    X_starts.append([])
                    Y_starts.append([])
                else:
                    X_starts.append(d[&#39;A&#39;][CLATH])
                    Y_starts.append(d[&#39;A&#39;][AUX])
            X_ends = []
            Y_ends = []
            for d in tracks[&#39;endBuffer&#39;]:
                if len(d) == 0:
                    X_ends.append([])
                    Y_ends.append([])
                else:
                    X_ends.append(d[&#39;A&#39;][CLATH])
                    Y_ends.append(d[&#39;A&#39;][AUX])
            X_extended = [X_starts[i] + X[i] + X_ends[i] for i in range(n)]

            # image feats
            pixel = np.array([[cla[int(t[i][j]), int(y_pos_seq[i][j]), int(x_pos_seq[i][j])]
                               if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                              for i in range(n)])
            pixel_up = np.array(
                [[cla[int(t[i][j]), min(int(y_pos_seq[i][j] + 1), cla.shape[1] - 1), int(x_pos_seq[i][j])]
                  if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                 for i in range(n)])
            pixel_down = np.array([[cla[int(t[i][j]), max(int(y_pos_seq[i][j] - 1), 0), int(x_pos_seq[i][j])]
                                    if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                                   for i in range(n)])
            pixel_left = np.array([[cla[int(t[i][j]), int(y_pos_seq[i][j]), max(int(x_pos_seq[i][j] - 1), 0)]
                                    if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                                   for i in range(n)])
            pixel_right = np.array(
                [[cla[int(t[i][j]), int(y_pos_seq[i][j]), min(int(x_pos_seq[i][j] + 1), cla.shape[2] - 1)]
                  if not math.isnan(t[i][j]) else 0 for j in range(len(tracks[&#39;t&#39;][i]))]
                 for i in range(n)])

            data = {
                &#39;X&#39;: X,
                &#39;X_extended&#39;: X_extended,
                &#39;Y&#39;: Y,
                &#39;X_starts&#39;: X_starts,
                &#39;Y_starts&#39;: Y_starts,
                &#39;X_ends&#39;: X_ends,
                &#39;Y_ends&#39;: Y_ends,
                &#39;X_pvals&#39;: X_pvals,
                &#39;Y_pvals&#39;: Y_pvals,
                &#39;catIdx&#39;: tracks[&#39;catIdx&#39;],
                &#39;mean_total_displacement&#39;: [totalDisplacement[i] / tracks[&#39;lifetime_s&#39;][i] for i in range(n)],
                &#39;mean_square_displacement&#39;: msd,
                &#39;lifetime&#39;: tracks[&#39;lifetime_s&#39;],
                &#39;lifetime_extended&#39;: [len(x) for x in X_extended],
                &#39;x_pos&#39;: [sum(x) / len(x) for x in x_pos_seq],  # mean position in the image
                &#39;y_pos&#39;: [sum(y) / len(y) for y in y_pos_seq],
                &#39;cell_num&#39;: [cell_num] * n,
                &#39;t&#39;: [t[i][0] for i in range(n)],
                &#39;x_pos_seq&#39;: x_pos_seq,
                &#39;y_pos_seq&#39;: y_pos_seq,
            }
            if all_data:
                data[&#39;t&#39;] = [t[i][0] for i in range(n)]
                data[&#39;pixel&#39;] = pixel
                data[&#39;pixel_left&#39;] = pixel_left
                data[&#39;pixel_right&#39;] = pixel_right
                data[&#39;pixel_up&#39;] = pixel_up
                data[&#39;pixel_down&#39;] = pixel_down
                data[&#39;center_max&#39;] = [max(pixel[i]) for i in range(n)],
                data[&#39;left_max&#39;] = [max(pixel_left[i]) for i in range(n)],
                data[&#39;right_max&#39;] = [max(pixel_right[i]) for i in range(n)],
                data[&#39;up_max&#39;] = [max(pixel_up[i]) for i in range(n)],
                data[&#39;down_max&#39;] = [max(pixel_down[i]) for i in range(n)],
            df = pd.DataFrame.from_dict(data)
            dfs.append(deepcopy(df))
    df = pd.concat(dfs)
    os.makedirs(os.path.dirname(processed_tracks_file), exist_ok=True)
    df.to_pickle(processed_tracks_file)
    return df</code></pre>
</details>
</dd>
<dt id="src.data.process_tracks_by_lifetime"><code class="name flex">
<span>def <span class="ident">process_tracks_by_lifetime</span></span>(<span>df, outcome_def, plot=False, acc_thresh=0.95, previous_meta_file=None)</span>
</code></dt>
<dd>
<section class="desc"><p>Calculate accuracy you can get by just predicting max class
as a func of lifetime and return points within proper lifetime (only looks at training cells)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_tracks_by_lifetime(df: pd.DataFrame, outcome_def: str,
                               plot=False, acc_thresh=0.95, previous_meta_file=None):
    &#39;&#39;&#39;Calculate accuracy you can get by just predicting max class 
    as a func of lifetime and return points within proper lifetime (only looks at training cells)
    &#39;&#39;&#39;
    vals = df[df.valid == 1][[&#39;lifetime&#39;, outcome_def]]

    R, C = 1, 3
    lifetimes = np.unique(vals[&#39;lifetime&#39;])

    # cumulative accuracy for different thresholds
    accs_cum_lower = np.array([1 - np.mean(vals[outcome_def][vals[&#39;lifetime&#39;] &lt;= l]) for l in lifetimes])
    accs_cum_higher = np.array([np.mean(vals[outcome_def][vals[&#39;lifetime&#39;] &gt;= l]) for l in lifetimes]).flatten()

    if previous_meta_file is None:
        try:
            idx_thresh = np.nonzero(accs_cum_lower &gt;= acc_thresh)[0][-1]  # last nonzero index
            thresh_lower = lifetimes[idx_thresh]
        except:
            idx_thresh = 0
            thresh_lower = lifetimes[idx_thresh] - 1
        try:
            idx_thresh_2 = np.nonzero(accs_cum_higher &gt;= acc_thresh)[0][0]
            thresh_higher = lifetimes[idx_thresh_2]
        except:
            idx_thresh_2 = lifetimes.size - 1
            thresh_higher = lifetimes[idx_thresh_2] + 1
    else:
        previous_meta = pkl.load(open(previous_meta_file, &#39;rb&#39;))
        thresh_lower = previous_meta[&#39;thresh_short&#39;]
        thresh_higher = previous_meta[&#39;thresh_long&#39;]

    # only df with lifetimes in proper range
    df[&#39;short&#39;] = df[&#39;lifetime&#39;] &lt;= thresh_lower
    df[&#39;long&#39;] = df[&#39;lifetime&#39;] &gt;= thresh_higher
    n = vals.shape[0]
    n_short = np.sum(df[&#39;short&#39;])
    n_long = np.sum(df[&#39;long&#39;])
    acc_short = 1 - np.mean(vals[outcome_def][vals[&#39;lifetime&#39;] &lt;= thresh_lower])
    acc_long = np.mean(vals[outcome_def][vals[&#39;lifetime&#39;] &gt;= thresh_higher])

    metadata = {&#39;num_short&#39;: n_short, &#39;num_long&#39;: n_long, &#39;acc_short&#39;: acc_short,
                &#39;acc_long&#39;: acc_long, &#39;thresh_short&#39;: thresh_lower, &#39;thresh_long&#39;: thresh_higher}

    if plot:
        plt.figure(figsize=(12, 4), dpi=200)
        plt.subplot(R, C, 1)
        outcome = df[outcome_def]
        plt.hist(df[&#39;lifetime&#39;][outcome == 1], label=&#39;aux+&#39;, alpha=1, color=cb, bins=25)
        plt.hist(df[&#39;lifetime&#39;][outcome == 0], label=&#39;aux-&#39;, alpha=0.7, color=cr, bins=25)
        plt.xlabel(&#39;lifetime&#39;)
        plt.ylabel(&#39;count&#39;)
        plt.legend()

        plt.subplot(R, C, 2)
        plt.plot(lifetimes, accs_cum_lower, color=cr)
        #     plt.axvline(thresh_lower)
        plt.axvspan(0, thresh_lower, alpha=0.2, color=cr)
        plt.ylabel(&#39;fraction of negative events&#39;)
        plt.xlabel(f&#39;lifetime &lt;= value\nshaded includes {n_short / n * 100:0.0f}% of pts&#39;)

        plt.subplot(R, C, 3)
        plt.plot(lifetimes, accs_cum_higher, cb)
        plt.axvspan(thresh_higher, max(lifetimes), alpha=0.2, color=cb)
        plt.ylabel(&#39;fraction of positive events&#39;)
        plt.xlabel(f&#39;lifetime &gt;= value\nshaded includes {n_long / n * 100:0.0f}% of pts&#39;)
        plt.tight_layout()

    return df, metadata</code></pre>
</details>
</dd>
<dt id="src.data.remove_invalid_tracks"><code class="name flex">
<span>def <span class="ident">remove_invalid_tracks</span></span>(<span>df, keep=[1, 2])</span>
</code></dt>
<dd>
<section class="desc"><p>Remove certain types of tracks based on cat_idx
cat_idx (idx 1 and 2)
1-4 (non-complex trajectory - no merges and splits)
1 - valid
2 - signal occasionally drops out
3 - cut
- starts / ends
4 - multiple - at the same place (continues throughout)
5-8 (there is merging or splitting)</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove_invalid_tracks(df, keep=[1, 2]):
    &#39;&#39;&#39;Remove certain types of tracks based on cat_idx
    cat_idx (idx 1 and 2)
        1-4 (non-complex trajectory - no merges and splits)
            1 - valid
            2 - signal occasionally drops out
            3 - cut  - starts / ends
            4 - multiple - at the same place (continues throughout)
        5-8 (there is merging or splitting)
    &#39;&#39;&#39;
    df[&#39;lifetime_ref&#39;] = [len(x) for x in df[&#39;X&#39;]]
    no_nan = df[&#39;lifetime&#39;] == df[&#39;lifetime_ref&#39;]
    df = df[no_nan]
    return df[df.catIdx.isin(keep)]</code></pre>
</details>
</dd>
<dt id="src.data.select_final_feats"><code class="name flex">
<span>def <span class="ident">select_final_feats</span></span>(<span>feat_names, binarize=False)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def select_final_feats(feat_names, binarize=False):
    feat_names = [x for x in feat_names
                  if not x.startswith(&#39;sc_&#39;)
                  and not x.startswith(&#39;nmf_&#39;)
                  and not x in [&#39;center_max&#39;, &#39;left_max&#39;, &#39;right_max&#39;, &#39;up_max&#39;, &#39;down_max&#39;,
                                &#39;X_max_around_Y_peak&#39;, &#39;X_max_after_Y_peak&#39;, &#39;X_max_diff_after_Y_peak&#39;]
                  and not x.startswith(&#39;pc_&#39;)
                  and not &#39;extended&#39; in x
                  #               and not &#39;X_peak&#39; in x
                  #               and not &#39;slope&#39; in x
                  #               and not x in [&#39;fall_final&#39;, &#39;fall_slope&#39;, &#39;fall_imp&#39;, &#39;fall&#39;]
                  ]
    feat_names = [x for x in feat_names if not &#39;_tf_smooth&#39; in x]
    feat_names = [x for x in feat_names if not &#39;local&#39; in x]
    feat_names = [x for x in feat_names if not &#39;last&#39; in x]
    # feat_names = [x for x in feat_names if &#39;_tf_smooth&#39; in x]

    if binarize:
        feat_names = [x for x in feat_names if &#39;binary&#39; in x]
    else:
        feat_names = [x for x in feat_names if not &#39;binary&#39; in x]
    return feat_names</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src" href="index.html">src</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.data.extract_X_mat" href="#src.data.extract_X_mat">extract_X_mat</a></code></li>
<li><code><a title="src.data.get_data" href="#src.data.get_data">get_data</a></code></li>
<li><code><a title="src.data.get_feature_names" href="#src.data.get_feature_names">get_feature_names</a></code></li>
<li><code><a title="src.data.get_images" href="#src.data.get_images">get_images</a></code></li>
<li><code><a title="src.data.get_tracks" href="#src.data.get_tracks">get_tracks</a></code></li>
<li><code><a title="src.data.process_tracks_by_lifetime" href="#src.data.process_tracks_by_lifetime">process_tracks_by_lifetime</a></code></li>
<li><code><a title="src.data.remove_invalid_tracks" href="#src.data.remove_invalid_tracks">remove_invalid_tracks</a></code></li>
<li><code><a title="src.data.select_final_feats" href="#src.data.select_final_feats">select_final_feats</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>